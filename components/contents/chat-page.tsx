"use client"

import type React from "react"

import { useRef, useState, useEffect, useCallback, useMemo, memo } from "react"
import { useRouter, useSearchParams } from "next/navigation"
import { useSession } from "next-auth/react"
import { LlmResponse } from "@/components/chat/llm-response"
import { UserRequest } from "@/components/chat/user-request"
import { ChatInput } from "@/components/chat/chat-input"
import { useTranslation } from "@/lib/i18n"
import { useModel } from "@/components/providers/model-provider"
import { Skeleton } from "@/components/ui/skeleton"
import { useIsMobile } from "@/hooks/use-mobile"
import { toast } from "sonner"

interface Message {
  id: string
  role: "user" | "assistant"
  content: string
  timestamp: Date
  isDeepResearch?: boolean
  deepResearchStepType?: 'step' | 'synthesis' | 'final'
  isDeepResearchComplete?: boolean
  hasDeepResearchError?: boolean
  deepResearchStepInfo?: Record<string, any>
}

interface ChatPageProps {
  chatId?: string
}

// Memoized message wrapper component
const MessageWrapper = memo(({ 
  message, 
  isNewMessage, 
  copiedMessageId, 
  likedMessages, 
  dislikedMessages, 
  isStreaming, 
  editingMessageId, 
  editingContent, 
  regeneratingMessageId,
  streamingMessageId,
  onCopy, 
  onLike, 
  onDislike, 
  onRegenerate, 
  onEdit, 
  onSave, 
  onCancel, 
  onRegenerateFromUser, 
  setEditingContent 
}: {
  message: Message
  isNewMessage: boolean
  copiedMessageId: string | null
  likedMessages: Set<string>
  dislikedMessages: Set<string>
  isStreaming: boolean
  editingMessageId: string | null
  editingContent: string
  regeneratingMessageId: string | null
  streamingMessageId: string | null
  onCopy: (content: string, messageId: string) => void
  onLike: (messageId: string) => void
  onDislike: (messageId: string) => void
  onRegenerate: (messageId: string) => void
  onEdit: (messageId: string, content: string) => void
  onSave: (messageId: string) => void
  onCancel: () => void
  onRegenerateFromUser: (messageId: string) => void
  setEditingContent: (content: string) => void
}) => {
  return (
    <div 
      className={`message-item mb-6 ${isNewMessage ? 'message-enter' : ''} ${message.role === "user" ? "flex justify-end" : ""}`}
    >
      {message.role === "assistant" && (
        <LlmResponse
          id={message.id}
          content={message.content}
          timestamp={message.timestamp}
          onCopy={onCopy}
          onLike={onLike}
          onDislike={onDislike}
          onRegenerate={onRegenerate}
          copiedMessageId={copiedMessageId}
          likedMessages={likedMessages}
          dislikedMessages={dislikedMessages}
          isStreaming={isStreaming && streamingMessageId === message.id}
          isDeepResearch={message.isDeepResearch}
          deepResearchStepType={message.deepResearchStepType}
          isDeepResearchComplete={message.isDeepResearchComplete}
          hasDeepResearchError={message.hasDeepResearchError}
          deepResearchStepInfo={message.deepResearchStepInfo}
        />
      )}

      {message.role === "user" && (
        <UserRequest
          id={message.id}
          content={message.content}
          timestamp={message.timestamp}
          onCopy={onCopy}
          onEdit={onEdit}
          onSave={onSave}
          onCancel={onCancel}
          onRegenerate={onRegenerateFromUser}
          editingMessageId={editingMessageId}
          editingContent={editingContent}
          setEditingContent={setEditingContent}
          copiedMessageId={copiedMessageId}
          isStreaming={isStreaming}
          regeneratingMessageId={regeneratingMessageId}
        />
      )}
    </div>
  )
}, (prevProps, nextProps) => {
  // Only rerender if message content hasn't changed and only state related to this message has changed
  const message = prevProps.message
  const nextMessage = nextProps.message
  
  // Message content has changed, rerender
  if (message.id !== nextMessage.id || message.content !== nextMessage.content) {
    return false
  }
  
  // Current message is streaming, rerender
  if (nextProps.streamingMessageId === message.id) {
    return false
  }
  
  // Current message is being edited, rerender
  if (nextProps.editingMessageId === message.id) {
    return false
  }
  
  // Current message is being regenerated or regeneration state changed, rerender
  if (nextProps.regeneratingMessageId === message.id || 
      prevProps.regeneratingMessageId === message.id) {
    return false
  }
  
  // Current message has been copied, rerender
  if (nextProps.copiedMessageId === message.id) {
    return false
  }
  
  // Current message is new, rerender
  if (nextProps.isNewMessage !== prevProps.isNewMessage) {
    return false
  }
  
  // Like/dislike state has changed, rerender
  if (nextProps.likedMessages.has(message.id) !== prevProps.likedMessages.has(message.id) ||
      nextProps.dislikedMessages.has(message.id) !== prevProps.dislikedMessages.has(message.id)) {
    return false
  }
  
  // Don't rerender in other cases
  return true
})

// Chat message skeleton component
const ChatMessageSkeleton = () => {
  return (
    <div className="space-y-6 animate-pulse">
      {/* First AI response skeleton */}
      <div className="flex justify-start mb-6">
        <div className="w-full max-w-[90%] space-y-2">
          <div className="flex items-center space-x-2">
            <div className="h-3 w-3 bg-gray-300 dark:bg-gray-600 rounded-full animate-skeleton-pulse"></div>
            <div className="h-3 w-16 bg-gray-300 dark:bg-gray-600 rounded animate-skeleton-pulse" style={{animationDelay: '0.1s'}}></div>
          </div>
          <div className="space-y-2">
            <div className="h-4 w-full bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.2s'}}></div>
            <div className="h-4 w-[95%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.3s'}}></div>
            <div className="h-4 w-[85%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.4s'}}></div>
            <div className="h-4 w-[92%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.5s'}}></div>
            <div className="h-4 w-[78%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.6s'}}></div>
          </div>
        </div>
      </div>

      {/* Second AI response skeleton */}
      <div className="flex justify-start mb-6">
        <div className="w-full max-w-[90%] space-y-2">
          <div className="flex items-center space-x-2">
            <div className="h-3 w-3 bg-gray-300 dark:bg-gray-600 rounded-full animate-skeleton-pulse" style={{animationDelay: '0.7s'}}></div>
            <div className="h-3 w-16 bg-gray-300 dark:bg-gray-600 rounded animate-skeleton-pulse" style={{animationDelay: '0.8s'}}></div>
          </div>
          <div className="space-y-2">
            <div className="h-4 w-[90%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.9s'}}></div>
            <div className="h-4 w-full bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.0s'}}></div>
            <div className="h-4 w-[87%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.1s'}}></div>
            <div className="h-4 w-[65%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.2s'}}></div>
          </div>
        </div>
      </div>

      {/* Third AI response skeleton */}
      <div className="flex justify-start mb-6">
        <div className="w-full max-w-[90%] space-y-2">
          <div className="flex items-center space-x-2">
            <div className="h-3 w-3 bg-gray-300 dark:bg-gray-600 rounded-full animate-skeleton-pulse" style={{animationDelay: '1.3s'}}></div>
            <div className="h-3 w-16 bg-gray-300 dark:bg-gray-600 rounded animate-skeleton-pulse" style={{animationDelay: '1.4s'}}></div>
          </div>
          <div className="space-y-2">
            <div className="h-4 w-[82%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.5s'}}></div>
            <div className="h-4 w-[96%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.6s'}}></div>
            <div className="h-4 w-full bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.7s'}}></div>
            <div className="h-4 w-[89%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.8s'}}></div>
            <div className="h-4 w-[75%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.9s'}}></div>
            <div className="h-4 w-[91%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '2.0s'}}></div>
            <div className="h-4 w-[68%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '2.1s'}}></div>
          </div>
        </div>
      </div>
    </div>
  )
}

export default function ChatPage({ chatId }: ChatPageProps) {
  const router = useRouter()
  const searchParams = useSearchParams()
  const { data: session, status: sessionStatus } = useSession()
  const { lang } = useTranslation('chat')
  const { selectedModel } = useModel()
  const isMobile = useIsMobile()
  const textareaRef = useRef<HTMLTextAreaElement>(null)
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const messagesContainerRef = useRef<HTMLDivElement>(null)
  const [inputValue, setInputValue] = useState("")
  const [isGlobeActive, setIsGlobeActive] = useState(false)
  const [isDeepResearchActive, setIsDeepResearchActive] = useState(false)
  const [isShiftPressed, setIsShiftPressed] = useState(false)
  const [messages, setMessages] = useState<Message[]>([])
  const [selectedMessageId, setSelectedMessageId] = useState<string | null>(null)
  const [editingMessageId, setEditingMessageId] = useState<string | null>(null)
  const [editingContent, setEditingContent] = useState("")

  const [copiedMessageId, setCopiedMessageId] = useState<string | null>(null)
  const [likedMessages, setLikedMessages] = useState<Set<string>>(new Set())
  const [dislikedMessages, setDislikedMessages] = useState<Set<string>>(new Set())
  const [historyLoaded, setHistoryLoaded] = useState(false)
  const [showSkeleton, setShowSkeleton] = useState(false)
  const [isStreaming, setIsStreaming] = useState(false)
  const [regeneratingMessageId, setRegeneratingMessageId] = useState<string | null>(null)
  const [forceUpdateCounter, setForceUpdateCounter] = useState(0)
  
  // Debug: ì¬ìƒì„± ìƒíƒœ ë³€ê²½ ì „ì—­ ì¶”ì 
  useEffect(() => {
    console.log('=== Global regeneratingMessageId changed ===')
    console.log('New regeneratingMessageId:', regeneratingMessageId)
    console.log('Current isStreaming:', isStreaming)
    
    // ì¬ìƒì„± ìƒíƒœê°€ ë³€ê²½ë  ë•Œ ê°•ì œ ë¦¬ë Œë”ë§ì„ ìœ„í•œ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
    console.log('=== Force re-render trigger ===')
    setForceUpdateCounter(prev => prev + 1)
  }, [regeneratingMessageId])
  const [newMessageIds, setNewMessageIds] = useState<Set<string>>(new Set())
  const [streamingMessageId, setStreamingMessageId] = useState<string | null>(null)
  const [uploadedImages, setUploadedImages] = useState<File[]>([])
  const [isSubmitting, setIsSubmitting] = useState(false)
  const [isComposing, setIsComposing] = useState(false)
  const [clearImagesTrigger, setClearImagesTrigger] = useState(false)
  const [deepResearchPlannedSteps, setDeepResearchPlannedSteps] = useState<Array<{ title: string, type: string }>>([])
  // Set safer initial value
  const [dynamicPadding, setDynamicPadding] = useState(() => {
    // Use default value on server side, detect screen size on client
    if (typeof window === 'undefined') return 240
    return window.innerWidth < 768 ? 320 : 160
  })
  
  // Ref to prevent React Strict Mode duplicate execution
  const streamingInProgress = useRef(false)
  const abortControllerRef = useRef<AbortController | null>(null)
  const isScrollingToBottom = useRef(false)
  const lastScrollHeight = useRef(0)
  const lastSubmittedMessage = useRef<string | null>(null)
  const lastSubmittedTime = useRef<number>(0)
  const isSubmittingRef = useRef(false) // ì¶”ê°€ì ì¸ ì¤‘ë³µ ë°©ì§€
  
  // Add ref to prevent duplicate deep research calls
  const deepResearchInProgress = useRef<Set<string>>(new Set())

  // Reset padding when isMobile changes
  useEffect(() => {
    if (isMobile !== undefined) {
      const basePadding = isMobile ? 320 : 160
      setDynamicPadding(basePadding)
    }
  }, [isMobile])

  // Detect message container height and adjust dynamic padding
  const adjustDynamicPadding = useCallback(() => {
    if (messagesContainerRef.current) {
      const container = messagesContainerRef.current
      const containerHeight = container.clientHeight
      const scrollHeight = container.scrollHeight
      const scrollTop = container.scrollTop
      
      // Only adjust padding when scroll is near bottom
      const isNearBottom = scrollHeight - scrollTop - containerHeight < 80
      
      if (isNearBottom) {
        // Check only code blocks in the last message (to prevent excessive padding)
        const lastMessage = container.querySelector('.max-w-3xl > div:last-child')
        let additionalPadding = 0
        
        if (lastMessage) {
          const codeBlocks = lastMessage.querySelectorAll('.code-block')
          if (codeBlocks.length > 0) {
            // Consider only the height of code blocks in the last message
            const lastCodeBlock = codeBlocks[codeBlocks.length - 1]
            const rect = lastCodeBlock.getBoundingClientRect()
            
            // Add additional padding only when code block height is over 150px
            if (rect.height > 150) {
              additionalPadding = Math.min(rect.height * 0.3, 100) // Max 100px additional padding
            }
          }
        }
        
        // Base padding + limited additional padding
        const basePadding = isMobile ? 320 : 160
        const newPadding = Math.max(basePadding, basePadding + additionalPadding)
        
        // Increase threshold to prevent unnecessary padding changes
        const threshold = 30
        
        if (Math.abs(newPadding - dynamicPadding) > threshold) {
          setDynamicPadding(newPadding)
        }
      } else {
        // Restore base padding when scroll is at top
        const basePadding = isMobile ? 320 : 160
        if (dynamicPadding > basePadding) {
          setDynamicPadding(basePadding)
        }
      }
    }
  }, [dynamicPadding, isMobile])

  // Generate unique ID
  const generateUniqueId = (prefix: string) => {
    return `${prefix}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
  }

  // Adjust padding and scroll when streaming stops
  const handleAbort = () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
      abortControllerRef.current = null
    }
    streamingInProgress.current = false
    setIsStreaming(false)
    setRegeneratingMessageId(null)
    setStreamingMessageId(null)
    
    // ìƒíƒœ ë¦¬ì…‹ì„ ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ í™•ì‹¤íˆ ì ìš©ë˜ë„ë¡ í•¨
    setTimeout(() => {
      console.log('=== handleAbort - First safety check ===')
      setRegeneratingMessageId(null)
      setIsStreaming(false)
    }, 100)
    
    setTimeout(() => {
      console.log('=== handleAbort - Final safety check ===')
      setRegeneratingMessageId(null)
      setIsStreaming(false)
    }, 500)
    
    // ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ì„ ì˜¬ë ¸ë‹¤ë©´ ê°•ì œ ìŠ¤í¬ë¡¤ ë°©ì§€
    const container = messagesContainerRef.current
    const userScrolled = (container as any)?.userScrolled?.() || false
    
    if (!userScrolled) {
      // ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ íŒ¨ë”© ì¡°ì • ë° ìŠ¤í¬ë¡¤
      adjustDynamicPadding()
      scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom
    }
  }

  // Handle image upload from ChatInput
  const handleImageUpload = useCallback((images: File[]) => {
    setUploadedImages(images)
  }, [])

  // Continue with new request after short delay
  // ë³‘ë ¬ ë”¥ë¦¬ì„œì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
  const handleParallelDeepResearch = async (
    subQuestions: string[],
    originalQuery: string,
    modelId: string,
    assistantMessageId: string,
    chatId?: string | number
  ) => {
    // Create unique key for this deep research session
    const deepResearchKey = `${assistantMessageId}_${originalQuery}_${modelId}`;
    
    try {
      console.log('ğŸš€ ========= HANDLE PARALLEL DEEP RESEARCH START =========');
      console.log('ğŸš€ Function called with parameters:');
      console.log('ğŸš€ - subQuestions:', subQuestions);
      console.log('ğŸš€ - subQuestions length:', subQuestions?.length);
      console.log('ğŸš€ - originalQuery:', originalQuery);
      console.log('ğŸš€ - modelId:', modelId);
      console.log('ğŸš€ - assistantMessageId:', assistantMessageId);
      console.log('ğŸš€ - chatId:', chatId);
      console.log('ğŸš€ - chatId type:', typeof chatId);
      console.log('ğŸš€ Starting parallel sub-question analysis');
      
      // Check if this deep research is already in progress
      if (deepResearchInProgress.current.has(deepResearchKey)) {
        console.log('ğŸš« Deep research already in progress for this session, skipping duplicate call');
        console.log('ğŸš« Key:', deepResearchKey);
        console.log('ğŸš« Active sessions:', Array.from(deepResearchInProgress.current));
        return;
      }
      
      // Mark this deep research as in progress
      deepResearchInProgress.current.add(deepResearchKey);
      console.log('âœ… Deep research session started:', deepResearchKey);
      
      // Check if sub-questions are available
      if (!subQuestions || subQuestions.length === 0) {
        console.error('âŒ No sub-questions provided for parallel deep research');
        console.error('âŒ This usually happens when the query is too simple or vague');
        console.error('âŒ Original query:', originalQuery);
        console.error('âŒ Received sub-questions:', subQuestions);
        deepResearchInProgress.current.delete(deepResearchKey); // Clean up on error
        
        // Update message with helpful error
        setMessages(prev => 
          prev.map(m => 
            m.id === assistantMessageId 
              ? { 
                  ...m,
                  content: m.content + '\n\nâš ï¸ ì§ˆë¬¸ì´ ë„ˆë¬´ ê°„ë‹¨í•˜ì—¬ ì„¸ë¶€ ë¶„ì„ ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n\nì˜ˆì‹œ: "í•œêµ­ì˜ ê²½ì œ ë°œì „ ê³¼ì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" ë˜ëŠ” "í•œêµ­ ë¬¸í™”ì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?"',
                  hasDeepResearchError: true,
                  isDeepResearchComplete: true
                }
              : m
          )
        );
        
        // Reset streaming state
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        isSubmittingRef.current = false;
        streamingInProgress.current = false;
        
        return;
      }
      
      // Generate unique IDs for each sub-question
      const subQuestionData = subQuestions.map((question, index) => ({
        id: `subq_${Date.now()}_${index}`,
        question,
        index
      }));
      
      console.log('Sub-question data with IDs:', subQuestionData);
      
      // ëª¨ë“  sub-questionì„ ë³‘ë ¬ë¡œ ë¶„ì„ (íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
      const analysisPromises = subQuestionData.map(async (subQuestionItem) => {
        const { id, question, index } = subQuestionItem;
        console.log(`ğŸ“Š Starting analysis ${index + 1} (${id}): ${question}`);
        
        // íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” fetch í•¨ìˆ˜
        const fetchWithTimeout = async (url: string, options: RequestInit, timeoutMs: number = 90000) => {
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
          
          try {
            const response = await fetch(url, {
              ...options,
              signal: controller.signal
            });
            clearTimeout(timeoutId);
            return response;
          } catch (error) {
            clearTimeout(timeoutId);
            if (controller.signal.aborted) {
              throw new Error(`Request timeout after ${timeoutMs / 1000} seconds`);
            }
            throw error;
          }
        };
        
        // ì¬ì‹œë„ ë¡œì§
        let lastError: Error | null = null;
        const maxRetries = 2;
        
        for (let attempt = 1; attempt <= maxRetries; attempt++) {
          try {
            console.log(`ğŸ“Š Attempt ${attempt}/${maxRetries} for analysis ${index + 1} (${id})`);
            
            const response = await fetchWithTimeout(`/api/deepresearch/subquestion-analysis`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                subQuestion: question,
                originalQuery,
                modelId,
                context: '',
                previousSteps: []
              })
            }, 90000); // 90ì´ˆ íƒ€ì„ì•„ì›ƒ (ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•´ ì‹œê°„ ì¦ê°€)

            if (!response.ok) {
              const errorText = await response.text();
              throw new Error(`Analysis failed (${response.status}): ${errorText}`);
            }

            const result = await response.json();
            console.log(`âœ… Completed analysis ${index + 1} (${id}) on attempt ${attempt}: ${question}`);
            console.log('ğŸ” Sub-question analysis result:', result);
            console.log('ğŸ” Sub-question analysis keys:', Object.keys(result));
            console.log('ğŸ” Sub-question analysis content:', result.analysis);
            
            // ê° ë¶„ì„ ì™„ë£Œ ì‹œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ - ê³ ìœ  IDë¡œ ë§¤í•‘
            setMessages(prev => 
              prev.map(m => 
                m.id === assistantMessageId 
                  ? { 
                      ...m,
                      deepResearchStepInfo: {
                        ...m.deepResearchStepInfo,
                        [id]: {
                          title: `Analysis: ${question}`,
                          content: result.analysis?.analysis || result.analysis || 'ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.',
                          isComplete: true,
                          index: index,
                          subQuestionId: id,
                          originalQuestion: question
                        }
                      }
                    }
                  : m
              )
            );
            
            return {
              analysis: result.analysis?.analysis || result.analysis || 'ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.',
              content: result.analysis?.analysis || result.analysis || 'ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.',
              subQuestionId: id,
              originalQuestion: question,
              index: index
            };
          } catch (error) {
            lastError = error instanceof Error ? error : new Error(String(error));
            console.error(`âŒ Failed analysis ${index + 1} (${id}) attempt ${attempt}:`, error);
            
            // ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
            if (attempt < maxRetries) {
              console.log(`â³ Retrying analysis ${index + 1} (${id}) in 2 seconds...`);
              await new Promise(resolve => setTimeout(resolve, 2000));
              continue;
            }
            
            // ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ìƒíƒœ ì—…ë°ì´íŠ¸
            setMessages(prev => 
              prev.map(m => 
                m.id === assistantMessageId 
                  ? { 
                      ...m,
                      deepResearchStepInfo: {
                        ...m.deepResearchStepInfo,
                        [id]: {
                          title: `Analysis: ${question}`,
                                                     content: `âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (${maxRetries}ë²ˆ ì‹œë„ ì‹¤íŒ¨): ${lastError?.message || 'Unknown error'}`,
                          isComplete: false,
                          hasError: true,
                          index: index,
                          subQuestionId: id,
                          originalQuestion: question
                        }
                      }
                    }
                  : m
              )
            );
            
            // ë¶€ë¶„ì  ì‹¤íŒ¨ëŠ” null ë°˜í™˜ (ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ)
            return null;
          }
        }
        
        return null; // ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
      });

      // ëª¨ë“  ë¶„ì„ ì™„ë£Œ ëŒ€ê¸°
      console.log('â³ Waiting for all analyses to complete...');
      const analysisResults = await Promise.all(analysisPromises);
      const validResults = analysisResults.filter(result => result !== null);
      
      console.log(`âœ… All analyses completed: ${validResults.length}/${subQuestions.length} successful`);
      console.log('Valid results:', validResults);
      console.log('Valid results details:', validResults.map(r => ({
        subQuestionId: r.subQuestionId,
        originalQuestion: r.originalQuestion,
        index: r.index,
        hasAnalysis: !!r.analysis,
        hasContent: !!r.content,
        analysisLength: r.analysis?.length || 0
      })));

      if (validResults.length === 0) {
        throw new Error('All sub-question analyses failed.');
      }

      // fetchWithTimeout í•¨ìˆ˜ ì •ì˜ (ë¨¼ì € ì •ì˜)
      const fetchWithTimeout = async (url: string, options: RequestInit, timeoutMs: number = 60000) => {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeoutMs);
        
        try {
          const response = await fetch(url, {
            ...options,
            signal: controller.signal
          });
          clearTimeout(timeoutId);
          return response;
        } catch (error) {
          clearTimeout(timeoutId);
          if (controller.signal.aborted) {
            throw new Error(`Request timeout after ${timeoutMs / 1000} seconds`);
          }
          throw error;
        }
      };

      // ì¢…í•© ë¶„ì„ ìˆ˜í–‰ (íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ í¬í•¨)
      console.log('ğŸ”„ Starting synthesis...');
      console.log('ğŸ”„ Valid results for synthesis:', validResults.length);
      console.log('ğŸ”„ Synthesis request data:', {
        query: originalQuery,
        modelId,
        analysisStepsCount: validResults.length
      });
      
      let synthesisResult: any = null;
      const synthesisMaxRetries = 3;
      let synthesisLastError: Error | null = null;
      
      for (let attempt = 1; attempt <= synthesisMaxRetries; attempt++) {
        try {
          console.log(`ğŸ”„ Synthesis attempt ${attempt}/${synthesisMaxRetries}`);
          
          const synthesisResponse = await fetchWithTimeout(`/api/deepresearch/synthesis`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              query: originalQuery,
              modelId,
              analysisSteps: validResults.map(result => ({
                analysis: result.analysis || result.content || result,
                subQuestion: result.originalQuestion,
                index: result.index
              }))
            })
          }, 90000); // 90ì´ˆ íƒ€ì„ì•„ì›ƒ (ì¢…í•© ë¶„ì„ì€ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)

          if (!synthesisResponse.ok) {
            const errorText = await synthesisResponse.text();
            throw new Error(`Synthesis failed (${synthesisResponse.status}): ${errorText}`);
          }

          synthesisResult = await synthesisResponse.json();
          console.log(`âœ… Synthesis completed on attempt ${attempt}`);
          break; // ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
        } catch (error) {
          synthesisLastError = error instanceof Error ? error : new Error(String(error));
          console.error(`âŒ Synthesis attempt ${attempt} failed:`, error);
          
          if (attempt < synthesisMaxRetries) {
            console.log(`â³ Retrying synthesis in 3 seconds...`);
            await new Promise(resolve => setTimeout(resolve, 3000));
          } else {
            throw new Error(`Synthesis failed after ${synthesisMaxRetries} attempts: ${synthesisLastError?.message || 'Unknown error'}`);
          }
        }
      }
      console.log('âœ… Synthesis completed:', synthesisResult);
      console.log('ğŸ” Synthesis result keys:', Object.keys(synthesisResult));
      console.log('ğŸ” Synthesis content:', synthesisResult.synthesis);

      // ì¢…í•© ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
      const synthesisId = `synthesis_${Date.now()}`;
      setMessages(prev => 
        prev.map(m => 
          m.id === assistantMessageId 
            ? { 
                ...m,
                deepResearchStepInfo: {
                  ...m.deepResearchStepInfo,
                  [synthesisId]: {
                    title: 'Synthesis Analysis',
                    content: synthesisResult.synthesis || 'ì¢…í•© ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.',
                    isComplete: true,
                    isSynthesis: true
                  }
                }
              }
            : m
        )
      );

      // ìµœì¢… ë‹µë³€ ìƒì„± (íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ í¬í•¨)
      console.log('ğŸ¯ Generating final answer...');
      console.log('ğŸ¯ Final answer request data:', {
        query: originalQuery,
        modelId,
        analysisStepsCount: validResults.length,
        synthesisLength: synthesisResult.synthesis?.length || 0
      });
      
      let finalAnswerResult: any = null;
      const finalAnswerMaxRetries = 3;
      let finalAnswerLastError: Error | null = null;
      
      for (let attempt = 1; attempt <= finalAnswerMaxRetries; attempt++) {
        try {
          console.log(`ğŸ¯ Final answer attempt ${attempt}/${finalAnswerMaxRetries}`);
          
          const finalAnswerResponse = await fetchWithTimeout(`/api/deepresearch/final-answer`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              query: originalQuery,
              modelId,
              analysisSteps: validResults.map(result => ({
                analysis: result.analysis || result.content || result,
                subQuestion: result.originalQuestion,
                index: result.index
              })),
              synthesis: synthesisResult.synthesis
            })
          }, 120000); // 120ì´ˆ íƒ€ì„ì•„ì›ƒ (ìµœì¢… ë‹µë³€ì€ ê°€ì¥ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)

          if (!finalAnswerResponse.ok) {
            const errorText = await finalAnswerResponse.text();
            throw new Error(`Final answer generation failed (${finalAnswerResponse.status}): ${errorText}`);
          }

          finalAnswerResult = await finalAnswerResponse.json();
          console.log(`ğŸ‰ Final answer generated on attempt ${attempt}`);
          break; // ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
        } catch (error) {
          finalAnswerLastError = error instanceof Error ? error : new Error(String(error));
          console.error(`âŒ Final answer attempt ${attempt} failed:`, error);
          
          if (attempt < finalAnswerMaxRetries) {
            console.log(`â³ Retrying final answer generation in 5 seconds...`);
            await new Promise(resolve => setTimeout(resolve, 5000));
          } else {
            throw new Error(`Final answer generation failed after ${finalAnswerMaxRetries} attempts: ${finalAnswerLastError?.message || 'Unknown error'}`);
          }
        }
      }
      console.log('ğŸ‰ ========= FINAL ANSWER GENERATION SUCCESS =========');
      console.log('ğŸ‰ Final answer generated successfully!');
      console.log('ğŸ‰ Final answer result:', finalAnswerResult);
      console.log('ğŸ‰ Final answer result keys:', Object.keys(finalAnswerResult));
      console.log('ğŸ‰ Final answer content:', finalAnswerResult.finalAnswer);
      console.log('ğŸ‰ Final answer length:', finalAnswerResult.finalAnswer?.length);

      // ìµœì¢… ë‹µë³€ìœ¼ë¡œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
      const finalAnswerId = `final_answer_${Date.now()}`;
      const finalAnswerContent = finalAnswerResult.finalAnswer || finalAnswerResult.answer || 'ìµœì¢… ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.';
      
      console.log('ğŸ‰ Final answer content extracted:');
      console.log('ğŸ‰ - finalAnswerId:', finalAnswerId);
      console.log('ğŸ‰ - finalAnswerContent length:', finalAnswerContent.length);
      console.log('ğŸ‰ - finalAnswerContent preview:', finalAnswerContent.substring(0, 100));
      console.log('ğŸ‰ ========= FINAL ANSWER GENERATION SUCCESS END =========');
      
      console.log('ğŸ” Final answer processing:');
      console.log('- assistantMessageId:', assistantMessageId);
      console.log('- finalAnswerId:', finalAnswerId);
      console.log('- finalAnswerContent length:', finalAnswerContent.length);
      console.log('- finalAnswerContent preview:', finalAnswerContent.substring(0, 100));
      
      setMessages(prev => {
        console.log('ğŸ” Current messages before final answer update:', prev.length);
        const targetMessage = prev.find(m => m.id === assistantMessageId);
        console.log('ğŸ” Target message found:', !!targetMessage);
        console.log('ğŸ” Target message content length:', targetMessage?.content.length);
        
        const updatedMessages = prev.map(m => 
          m.id === assistantMessageId 
            ? { 
                ...m,
                // Replace content with final answer for llm-response display
                content: finalAnswerContent,
                isDeepResearchComplete: true,
                deepResearchStepType: 'final' as const, // Set as final answer step
                deepResearchStepInfo: {
                  ...m.deepResearchStepInfo,
                  [finalAnswerId]: {
                    title: 'Final Answer',
                    content: '', // Empty content for Final Answer block
                    isComplete: true,
                    isFinalAnswer: true
                  }
                }
              }
            : m
        );
        
        console.log('ğŸ” Updated messages after final answer:', updatedMessages.length);
        const updatedTargetMessage = updatedMessages.find(m => m.id === assistantMessageId);
        console.log('ğŸ” Updated target message content length:', updatedTargetMessage?.content.length);
        
        return updatedMessages;
      });

      console.log('ğŸ¯ ========= FINAL ANSWER PROCESSING COMPLETED =========');
      console.log('ğŸ¯ Final answer has been added to deepResearchStepInfo and will be displayed in Deep Research component');
      console.log('ğŸ¯ Final answer content length:', finalAnswerContent.length);
      
      // Note: We no longer save final answer as a separate message
      // It's displayed as part of the Deep Research component via deepResearchStepInfo
      
      console.log('ğŸ’¾ ========= FINAL ANSWER SAVE ATTEMPT END =========');

      // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¦‰ì‹œ ì¢…ë£Œ
      console.log('ğŸ”„ Ending streaming state immediately...');
      setIsStreaming(false);
      setStreamingMessageId(null);
      setIsSubmitting(false); // ì œì¶œ ìƒíƒœë„ í•´ì œ
      isSubmittingRef.current = false; // Refë„ í•¨ê»˜ ë¦¬ì…‹
      streamingInProgress.current = false;
      
      // ì¶”ê°€ ì•ˆì „ì¥ì¹˜ - ì—¬ëŸ¬ ë²ˆ ì‹œë„
      setTimeout(() => {
        console.log('ğŸ”„ Second attempt to end streaming state...');
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        isSubmittingRef.current = false;
        streamingInProgress.current = false;
      }, 100);
      
      setTimeout(() => {
        console.log('ğŸ”„ Final attempt to end streaming state...');
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        isSubmittingRef.current = false;
        streamingInProgress.current = false;
      }, 1000);

      console.log('ğŸ‰ Parallel deep research completed successfully!');
      
      // Clean up - remove from active sessions
      deepResearchInProgress.current.delete(deepResearchKey);
      console.log('ğŸ§¹ Cleaned up deep research session:', deepResearchKey);
      console.log('ğŸ§¹ Remaining active sessions:', Array.from(deepResearchInProgress.current));
      
    } catch (error) {
      console.error('âŒ Parallel deep research error:', error);
      console.error('âŒ Error stack:', error instanceof Error ? error.stack : 'No stack trace');
      console.error('âŒ Error details:', {
        message: error instanceof Error ? error.message : String(error),
        assistantMessageId,
        originalQuery,
        modelId
      });
      
      // ì—ëŸ¬ ì²˜ë¦¬
      const errorContent = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      setMessages(prev => 
        prev.map(m => 
          m.id === assistantMessageId 
            ? { 
                ...m,
                content: m.content + '\n\nâš ï¸ ë³‘ë ¬ ë”¥ë¦¬ì„œì¹˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + errorContent,
                hasDeepResearchError: true
              }
            : m
        )
      );
      
      // Clean up - remove from active sessions on error
      deepResearchInProgress.current.delete(deepResearchKey);
      console.log('ğŸ§¹ Cleaned up deep research session due to error:', deepResearchKey);
      
      // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¦‰ì‹œ ì¢…ë£Œ (ì—ëŸ¬ ì‹œ)
      console.log('ğŸ”„ Ending streaming state due to error...');
      setIsStreaming(false);
      setStreamingMessageId(null);
      setIsSubmitting(false); // ì œì¶œ ìƒíƒœë„ í•´ì œ
      isSubmittingRef.current = false; // Refë„ í•¨ê»˜ ë¦¬ì…‹
      streamingInProgress.current = false;
      
      // ì¶”ê°€ ì•ˆì „ì¥ì¹˜
      setTimeout(() => {
        console.log('ğŸ”„ Second attempt to end streaming state (error)...');
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        isSubmittingRef.current = false;
        streamingInProgress.current = false;
      }, 100);
    }
  };

  const sendMessageToAI = async (message: string, agentInfo: {id: string, type: string}, isRegeneration: boolean = false, images?: File[]) => {
    console.log('=== sendMessageToAI function called ===')
    console.log('message:', message)
    console.log('agentInfo:', agentInfo)
    console.log('isRegeneration:', isRegeneration)
    console.log('images:', images)
    console.log('session?.user?.email:', session?.user?.email)
    
    if (!session?.user?.email) {
      console.error('User authentication required')
      return
    }

    // Abort if already streaming and start new request
    if (streamingInProgress.current) {
      handleAbort()
      // Wait briefly after message update
      await new Promise(resolve => setTimeout(resolve, 100))
    }

    // Enhanced duplicate prevention using message content + timestamp + deep research state
    const currentTime = Date.now()
    const messageKey = `${message}_${images?.length || 0}_${isRegeneration}_${isDeepResearchActive}`
    const lastMessageData = sessionStorage.getItem(`lastMessage_${chatId}`)
    
    if (lastMessageData) {
      try {
        const { message: lastMsg, timestamp: lastTime } = JSON.parse(lastMessageData)
        // Block if same message within 3 seconds (increased for deep research)
        if (lastMsg === messageKey && currentTime - lastTime < 3000) {
          console.log('Duplicate AI request blocked:', messageKey)
          return
        }
      } catch (e) {
        // If parsing fails, continue with old logic
        if (lastMessageData === messageKey) {
          console.log('Duplicate AI request blocked (fallback):', messageKey)
          return
        }
      }
    }
    
    sessionStorage.setItem(`lastMessage_${chatId}`, JSON.stringify({
      message: messageKey,
      timestamp: currentTime
    }))

    // Abort previous request if exists
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
    }

    // Create new AbortController
    const abortController = new AbortController()
    abortControllerRef.current = abortController
    streamingInProgress.current = true
    setIsStreaming(true)
    
    // Adjust padding and scroll
    adjustDynamicPadding()
    scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom

    try {
      let response: Response

      if (images && images.length > 0) {
        // Use FormData when images are present
        const formData = new FormData()
        formData.append('message', message)
        if (agentInfo.type === 'agent') {
          formData.append('agentId', agentInfo.id)
        } else {
          formData.append('modelId', agentInfo.id)
        }
        formData.append('modelType', agentInfo.type)
        formData.append('isRegeneration', isRegeneration.toString())
        formData.append('isDeepResearchActive', isDeepResearchActive.toString())
        formData.append('isGlobeActive', isGlobeActive.toString())
        
        // Add image files
        images.forEach((image) => {
          formData.append('images', image)
        })
        
        // Add userId for authentication
        formData.append('userId', session?.user?.email || '')
        
        response = await fetch(`/api/chat/${chatId}`, {
          method: 'POST',
          body: formData
        })
      } else {
        // Use JSON for text-only messages
        response = await fetch(`/api/chat/${chatId}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            message,
            agentId: agentInfo.type === 'agent' ? agentInfo.id : undefined,
            modelId: agentInfo.type === 'model' ? agentInfo.id : undefined,
            modelType: agentInfo.type,
            isRegeneration,
            isDeepResearchActive,
            isGlobeActive,
            userId: session?.user?.email
          })
        })
      }

      if (!response.ok) {
        const errorText = await response.text()
        console.error('API response error:', errorText)
        
        // Parse error message from response
        let errorMessage = 'Message sending failed'
        try {
          const errorData = JSON.parse(errorText)
          if (errorData.error) {
            errorMessage = errorData.error
          }
        } catch (e) {
          // If parsing fails, use the raw error text
          errorMessage = errorText || `HTTP ${response.status} Error`
        }
        
        throw new Error(errorMessage)
      }

      // Process streaming response
      const reader = response.body?.getReader()
      const decoder = new TextDecoder()

      if (reader) {
        let assistantContent = ''
        let assistantMessageId = ''
        let storedChatId: string | number | undefined = undefined
        let storedDeepResearchData: any = null // Deep research data ì €ì¥ìš©

        const processStream = async () => {
          try {
            while (true) {
              if (abortController.signal.aborted) {
                break
              }

              const { done, value } = await reader.read()
              if (done) {
                break
              }

              const chunk = decoder.decode(value)
              const lines = chunk.split('\n')

              for (const line of lines) {
                if (line.startsWith('data: ')) {
                  try {
                    const data = JSON.parse(line.slice(6))
                    
                    if (data.error) {
                      console.error('AI response error:', data.error)
                      break
                    }

                    if (data.messageId && !assistantMessageId) {
                      assistantMessageId = data.messageId
                      setStreamingMessageId(assistantMessageId)
                      // Add new message ID
                      setNewMessageIds(prev => new Set([...prev, assistantMessageId]))
                      // Initialize AI response message
                      setMessages(prev => [...prev, {
                        id: assistantMessageId,
                        role: "assistant" as const,
                        content: '',
                        timestamp: new Date(),
                      }])
                      // ìƒˆ AI ì‘ë‹µ ë©”ì‹œì§€ ìƒì„± ì‹œ ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ìŠ¤í¬ë¡¤
                      const container = messagesContainerRef.current
                      const userScrolled = (container as any)?.userScrolled?.() || false
                      
                      if (!userScrolled) {
                        adjustDynamicPadding()
                        scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom
                      }
                    }

                    if (data.content) {
                      assistantContent += data.content
                      // Real-time update of AI response
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { ...m, content: assistantContent }
                            : m
                        )
                      )
                      // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ íŒ¨ë”© ì¡°ì • ë° ìŠ¤í¬ë¡¤
                      if (assistantContent.length % 100 === 0) {
                        const container = messagesContainerRef.current
                        const userScrolled = (container as any)?.userScrolled?.() || false
                        
                        if (!userScrolled) {
                          adjustDynamicPadding()
                          scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom
                        }
                      }
                    }

                    // Handle parallel processing started signal (ì²˜ë¦¬ ìˆœì„œ ë³€ê²½)
                    if (data.parallelProcessingStarted && data.chatId) {
                      console.log('ğŸš€ ========= PARALLEL PROCESSING STARTED SIGNAL =========');
                      console.log('ğŸš€ Parallel processing started signal received');
                      console.log('ğŸš€ Chat ID from parallel signal:', data.chatId);
                      console.log('ğŸš€ Message ID:', data.messageId);
                      console.log('ğŸš€ Full data:', data);
                      
                      // Store chatId for later use in parallel processing
                      storedChatId = data.chatId; // chatIdë¥¼ ì €ì¥ (dbMessageId ëŒ€ì‹ )
                      console.log('ğŸš€ Stored Chat ID:', storedChatId);
                      
                      // ì €ì¥ëœ Deep Research ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘
                      if (storedDeepResearchData && storedDeepResearchData.stepInfo?.useParallelProcessing && storedDeepResearchData.stepInfo?.subQuestions) {
                        console.log('ğŸš€ Starting parallel processing with stored data');
                        console.log('ğŸš€ Stored deep research data:', storedDeepResearchData);
                        
                        // Sub-questionsë¥¼ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ì¥
                        assistantContent += storedDeepResearchData.content;
                        
                        // ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘
                        console.log('ğŸš€ About to call handleParallelDeepResearch from stored data...');
                        
                        handleParallelDeepResearch(
                          storedDeepResearchData.stepInfo.subQuestions,
                          storedDeepResearchData.stepInfo.originalQuery,
                          storedDeepResearchData.stepInfo.modelId,
                          assistantMessageId,
                          storedChatId
                        );
                        
                        console.log('ğŸš€ handleParallelDeepResearch called from stored data');
                        
                        // ì €ì¥ëœ ë°ì´í„° ì´ˆê¸°í™”
                        storedDeepResearchData = null;
                      } else {
                        console.log('ğŸš€ No stored deep research data available for parallel processing');
                        console.log('ğŸš€ storedDeepResearchData:', storedDeepResearchData);
                      }
                      
                      console.log('ğŸš€ ========= PARALLEL PROCESSING STARTED SIGNAL END =========');
                    }

                    // Handle Deep Research streaming
                    if (data.deepResearchStream) {
                      console.log('ğŸš€ Deep Research Stream received:', data);
                      
                      // ê³„íšëœ ìŠ¤íƒ­ë“¤ ì²˜ë¦¬
                      if (data.stepInfo && data.stepInfo.plannedSteps) {
                        setDeepResearchPlannedSteps(data.stepInfo.plannedSteps)
                      }
                      
                      // ë³‘ë ¬ ì²˜ë¦¬ìš© ë°ì´í„° ì €ì¥
                      if (data.stepInfo?.useParallelProcessing && data.stepInfo?.subQuestions) {
                        console.log('ğŸš€ Storing deep research data for later parallel processing');
                        storedDeepResearchData = data;
                        console.log('ğŸš€ Stored deep research data:', storedDeepResearchData);
                      }
                      
                      // ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ í™•ì¸
                      if (data.stepInfo?.useParallelProcessing && data.stepInfo?.subQuestions) {
                        console.log('ğŸš€ ========= PARALLEL PROCESSING TRIGGER =========');
                        console.log('ğŸš€ Parallel processing condition met!');
                        console.log('ğŸš€ data.stepInfo?.useParallelProcessing:', data.stepInfo?.useParallelProcessing);
                        console.log('ğŸš€ data.stepInfo?.subQuestions length:', data.stepInfo?.subQuestions?.length);
                        console.log('ğŸš€ Step info:', data.stepInfo);
                        console.log('ğŸš€ Sub-questions from step info:', data.stepInfo.subQuestions);
                        console.log('ğŸš€ Assistant message ID:', assistantMessageId);
                        console.log('ğŸš€ Chat ID from data:', data.chatId);
                        console.log('ğŸš€ Stored Chat ID:', storedChatId);
                        
                        // Sub-questionsë¥¼ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ì¥
                        assistantContent += data.content;
                        
                        // ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì €ì¥ëœ Chat ID ì‚¬ìš©)
                        const finalChatId = storedChatId || data.chatId;
                        console.log('ğŸš€ Final Chat ID to use:', finalChatId);
                        console.log('ğŸš€ Final Chat ID type:', typeof finalChatId);
                        
                        console.log('ğŸš€ About to call handleParallelDeepResearch...');
                        console.log('ğŸš€ Parameters:');
                        console.log('ğŸš€ - subQuestions:', data.stepInfo.subQuestions);
                        console.log('ğŸš€ - originalQuery:', data.stepInfo.originalQuery);
                        console.log('ğŸš€ - modelId:', data.stepInfo.modelId);
                        console.log('ğŸš€ - assistantMessageId:', assistantMessageId);
                        console.log('ğŸš€ - finalChatId:', finalChatId);
                        
                        handleParallelDeepResearch(
                          data.stepInfo.subQuestions,
                          data.stepInfo.originalQuery,
                          data.stepInfo.modelId,
                          assistantMessageId,
                          finalChatId
                        );
                        
                        console.log('ğŸš€ handleParallelDeepResearch called successfully');
                        console.log('ğŸš€ ========= PARALLEL PROCESSING TRIGGER END =========');
                      } else {
                        console.log('ğŸš€ ========= PARALLEL PROCESSING NOT TRIGGERED =========');
                        console.log('ğŸš€ Reason: Parallel processing condition not met');
                        console.log('ğŸš€ data.stepInfo?.useParallelProcessing:', data.stepInfo?.useParallelProcessing);
                        console.log('ğŸš€ data.stepInfo?.subQuestions:', data.stepInfo?.subQuestions);
                        console.log('ğŸš€ data.stepInfo?.subQuestions length:', data.stepInfo?.subQuestions?.length);
                        console.log('ğŸš€ data.stepInfo full object:', data.stepInfo);
                        console.log('ğŸš€ ========= PARALLEL PROCESSING NOT TRIGGERED END =========');
                        
                        // ê¸°ì¡´ ìˆœì°¨ ì²˜ë¦¬ ë¡œì§
                        // ìŠ¤íƒ­ë³„ ì²˜ë¦¬: Sub-questionsì™€ ìµœì¢…ë‹µë³€(final)ì„ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ì¥
                        if (data.stepType === 'final' || 
                            (data.stepType === 'step' && data.stepInfo?.title === 'Sub-questions Generated')) {
                          // Sub-questionsì™€ ìµœì¢…ë‹µë³€ì€ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ì¥í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ
                          assistantContent += data.content
                        }
                        // ë‹¤ë¥¸ ë¶„ì„ ê³¼ì •(step, synthesis)ì€ ë©”ì‹œì§€ ë‚´ìš©ì— ì €ì¥í•˜ì§€ ì•ŠìŒ (ë”¥ë¦¬ì„œì¹˜ ì»´í¬ë„ŒíŠ¸ì—ì„œë§Œ í‘œì‹œ)
                      }
                      
                      // Real-time update of AI response with deep research streaming
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { 
                                ...m, 
                                content: assistantContent, 
                                isDeepResearch: true, 
                                deepResearchStepType: data.stepType,
                                deepResearchStepInfo: {
                                  ...data.stepInfo || {},
                                  plannedSteps: deepResearchPlannedSteps.length > 0 ? deepResearchPlannedSteps : data.stepInfo?.plannedSteps,
                                  currentStepContent: data.content,
                                  currentStepType: data.stepType
                                }
                              }
                            : m
                        )
                      )
                      // ë”¥ë¦¬ì„œì¹˜ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ë” ìì£¼ ìŠ¤í¬ë¡¤
                      const container = messagesContainerRef.current
                      const userScrolled = (container as any)?.userScrolled?.() || false
                      
                      if (!userScrolled) {
                        adjustDynamicPadding()
                        scrollToBottomSmooth(true)
                      }
                    }

                    // Handle Deep Research final result
                    if (data.deepResearchFinal) {
                      assistantContent = data.content // ìµœì¢… ê²°ê³¼ë¡œ ì™„ì „íˆ ëŒ€ì²´
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { ...m, content: assistantContent, isDeepResearch: true, isDeepResearchComplete: true }
                            : m
                        )
                      )
                      const container = messagesContainerRef.current
                      const userScrolled = (container as any)?.userScrolled?.() || false
                      
                      if (!userScrolled) {
                        adjustDynamicPadding()
                        scrollToBottomSmooth(true)
                      }
                    }

                    // Handle Deep Research error
                    if (data.deepResearchError) {
                      assistantContent += data.content
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { ...m, content: assistantContent, isDeepResearch: true, hasDeepResearchError: true }
                            : m
                        )
                      )
                      const container = messagesContainerRef.current
                      const userScrolled = (container as any)?.userScrolled?.() || false
                      
                      if (!userScrolled) {
                        adjustDynamicPadding()
                        scrollToBottomSmooth(true)
                      }
                    }

                    if (data.titleGenerated) {
                      // Title has been generated, immediately refresh sidebar
                      const eventDetail = { chatId: data.chatId, title: data.title }
                      window.dispatchEvent(new CustomEvent('chatTitleUpdated', { 
                        detail: eventDetail
                      }))
                    }

                    if (data.done) {
                      console.log('=== Streaming completed (data.done=true) ===')
                      
                      // ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œì ì—ì„œ ì¦‰ì‹œ ìƒíƒœ ë¦¬ì…‹
                      console.log('=== Immediate state reset on streaming completion ===')
                      setIsStreaming(false)
                      setIsSubmitting(false)
                      isSubmittingRef.current = false
                      setRegeneratingMessageId(null)
                      setStreamingMessageId(null)
                      streamingInProgress.current = false
                      
                      break
                    }
                  } catch (e) {
                    // Ignore JSON parsing errors
                  }
                }
              }
            }
          } catch (error) {
            if (error instanceof Error && error.name === 'AbortError') {
              // Stream processing aborted
            } else {
              console.error('Stream processing error:', error)
            }
          }
        }

        await processStream()
      }
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        // AI message sending aborted
      } else {
        console.error('AI message sending error:', error)
        // Show error toast to user
        const errorMessage = error instanceof Error ? error.message : 'An unexpected error occurred'
        toast.error(errorMessage)
        
        // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì¬ìƒì„± ìƒíƒœ ë¦¬ì…‹
        console.log('Resetting regenerating state due to error')
        setRegeneratingMessageId(null)
      }
    } finally {
      console.log('=== sendMessageToAI finally block ===')
      console.log('Resetting all streaming states')
      
      // ì¦‰ì‹œ ìƒíƒœ ë¦¬ì…‹
      streamingInProgress.current = false
      setIsStreaming(false)
      setIsSubmitting(false)
      isSubmittingRef.current = false
      setRegeneratingMessageId(null)
      setStreamingMessageId(null)
      abortControllerRef.current = null
      console.log('All streaming states reset')
      
      // ìƒíƒœ ë¦¬ì…‹ì„ ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ í™•ì‹¤íˆ ì ìš©ë˜ë„ë¡ í•¨
      setTimeout(() => {
        console.log('=== First safety check - Reset regeneration state ===')
        setRegeneratingMessageId(null)
        setIsStreaming(false)
        setIsSubmitting(false)
        isSubmittingRef.current = false
      }, 100)
      
      setTimeout(() => {
        console.log('=== Second safety check - Reset regeneration state ===')
        setRegeneratingMessageId(null)
        setIsSubmitting(false)
        isSubmittingRef.current = false
        setIsStreaming(false)
      }, 500)
      
      setTimeout(() => {
        console.log('=== Final safety check - Force reset regeneration state ===')
        setRegeneratingMessageId(null)
        setIsStreaming(false)
        setIsSubmitting(false)
        isSubmittingRef.current = false
      }, 1000) // 1ì´ˆ í›„ ê°•ì œ ë¦¬ì…‹
      
      // ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ì„ ì˜¬ë ¸ë‹¤ë©´ ê°•ì œ ìŠ¤í¬ë¡¤ ë°©ì§€
      const container = messagesContainerRef.current
      const userScrolled = (container as any)?.userScrolled?.() || false
      
      if (!userScrolled) {
        // ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ìµœì¢… íŒ¨ë”© ì¡°ì • ë° ìŠ¤í¬ë¡¤
        adjustDynamicPadding()
        scrollToBottomSmooth(true) // Force scroll
        
        // ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ í•œ ë²ˆë§Œ ì¶”ê°€ ìŠ¤í¬ë¡¤ (DOM ì—…ë°ì´íŠ¸ ëŒ€ê¸°)
        setTimeout(() => {
          if (!(container as any)?.userScrolled?.()) {
            scrollToBottomSmooth()
          }
        }, 100)
      }
      
      // ë² ì´ìŠ¤ íŒ¨ë”© ë³µì› (ì§€ì—° ì‹œê°„ ì¦ê°€)
      setTimeout(() => {
        setDynamicPadding(isMobile ? 320 : 160)
      }, 3000) // 3ì´ˆ í›„ ë³µì›í•˜ì—¬ ì‚¬ìš©ì ìŠ¤í¬ë¡¤ ë°©í•´ ìµœì†Œí™”
      
      // Clear duplicate prevention after request completes
      setTimeout(() => {
        sessionStorage.removeItem(`lastMessage_${chatId}`)
      }, 3000) // Clear after 3 seconds
    }
  }

  // Load chat history when chatId or session changes
  useEffect(() => {
    let isCancelled = false
    
    console.log('=== ChatPage useEffect triggered ===')
    console.log('chatId:', chatId)
    console.log('session?.user?.email:', session?.user?.email)
    console.log('sessionStatus:', sessionStatus)
    
    // Initialize loading state
    setHistoryLoaded(false)
    setShowSkeleton(true)
    
    // Ensure minimum skeleton UI display time (300ms)
    const minSkeletonDisplayTime = 300
    const skeletonStartTime = Date.now()
    
    if (chatId && session?.user?.email) {
      // Get chat history from API
      const loadChatHistory = async () => {
        if (isCancelled) return

        try {
          console.log('=== Fetching chat history ===')
          console.log('URL:', `/api/chat/${chatId}`)
          const response = await fetch(`/api/chat/${chatId}`)
          console.log('Response status:', response.status)
          if (isCancelled) return
          
          if (response.status === 401 || response.status === 404) {
            // ì¸ì¦ ì˜¤ë¥˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì—†ìŒ ì‹œ í™ˆí˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
            console.log('Chat session not found or access denied, redirecting to home')
            toast.error('ì±„íŒ… ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™ˆìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.')
            router.push('/')
            return
          }
          
          if (response.ok) {
            const data = await response.json()
            console.log('Chat history data:', data)
            if (isCancelled) return
            
            // Convert timestamp to Date object and process rating info
            const messagesWithDateTimestamp = (data.messages || []).map((msg: any) => {
              // Handle timestamp conversion properly for SQLite (integer) and PostgreSQL (string)
              let timestamp: Date;
              if (msg.timestamp) {
                // If timestamp is a number (SQLite), it's already in milliseconds
                // If timestamp is a string (PostgreSQL), Date constructor can handle it
                timestamp = new Date(msg.timestamp);
                // Check if the date is valid
                if (isNaN(timestamp.getTime())) {
                  // If invalid, use current time as fallback
                  timestamp = new Date();
                }
              } else {
                // If no timestamp, use current time
                timestamp = new Date();
              }
              
              return {
                ...msg,
                timestamp
              };
            })
            console.log('Processed messages:', messagesWithDateTimestamp)
            
            // Load rating information from messages
            const likedMessageIds = new Set<string>()
            const dislikedMessageIds = new Set<string>()
            
            messagesWithDateTimestamp.forEach((msg: any) => {
              if (msg.rating === 1) {
                likedMessageIds.add(msg.id)
              } else if (msg.rating === -1) {
                dislikedMessageIds.add(msg.id)
              }
            })
            
            // Update rating states
            setLikedMessages(likedMessageIds)
            setDislikedMessages(dislikedMessageIds)
            
            // Process messages in a non-blocking way
            const processMessages = () => {
              return new Promise<void>((resolve) => {
                if (isCancelled) {
                  resolve()
                  return
                }
                
                // Process messages consistently regardless of count
                // Set messages directly instead of initializing with empty array
                setMessages(messagesWithDateTimestamp)
                console.log('Messages set, length:', messagesWithDateTimestamp.length)
                
                // Auto-generate AI response if last message is user message AND there's agent info in localStorage
                // This only happens for newly created chats where user message was just sent
                const agentInfo = localStorage.getItem(`chat_${chatId}_agent`)
                if (messagesWithDateTimestamp.length > 0 && !streamingInProgress.current && agentInfo) {
                  const lastMessage = messagesWithDateTimestamp[messagesWithDateTimestamp.length - 1]
                  
                  // Only generate response if:
                  // 1. Last message is from user
                  // 2. There's exactly 1 message (first conversation)
                  // 3. Agent info exists in localStorage
                  if (lastMessage.role === 'user' && messagesWithDateTimestamp.length === 1) {
                    if (!isCancelled) {
                      const parsedAgentInfo = JSON.parse(agentInfo)
                      
                      // Call streaming API with isRegeneration=true to prevent duplicate user message saving
                      sendMessageToAI(lastMessage.content, parsedAgentInfo, true)
                      
                      // Clean up localStorage after use (delay to prevent race condition)
                      setTimeout(() => {
                        localStorage.removeItem(`chat_${chatId}_agent`)
                      }, 1000)
                    }
                  } else {
                    // Clean up localStorage if it exists but we're not using it
                    localStorage.removeItem(`chat_${chatId}_agent`)
                  }
                }
                
                // Always resolve the promise
                resolve()
              })
            }
            
            // Process messages asynchronously
            await processMessages()
          } else {
            console.error('Failed to load chat history')
            console.error('Response status:', response.status)
            const errorText = await response.text()
            console.error('Error response:', errorText)
          }
        } catch (error) {
          if (!isCancelled) {
            console.error('Chat history load error:', error)
          }
        } finally {
          if (!isCancelled) {
            // Ensure minimum skeleton UI display time (300ms)
            const elapsedTime = Date.now() - skeletonStartTime
            const remainingTime = Math.max(0, minSkeletonDisplayTime - elapsedTime)
            
            setTimeout(() => {
              if (!isCancelled) {
                // Prevent render blocking when there are many messages
                requestAnimationFrame(() => {
                  setHistoryLoaded(true) // Mark history load as completed
                  setShowSkeleton(false) // Hide skeleton UI
                  console.log('=== History loading completed ===')
                  console.log('historyLoaded: true, showSkeleton: false')
                  
                  // Move to bottom immediately after content is loaded (without animation)
                  // ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ìŠ¤í¬ë¡¤ ì²˜ë¦¬í•˜ì—¬ í™•ì‹¤í•˜ê²Œ ë§¨ ë°‘ìœ¼ë¡œ ì´ë™
                  setTimeout(() => {
                    scrollToBottomInstant()
                  }, 100)
                  
                  // ì¶”ê°€ ìŠ¤í¬ë¡¤ ì²˜ë¦¬ - DOM ì™„ì „ ë Œë”ë§ í›„
                  setTimeout(() => {
                    scrollToBottomInstant()
                  }, 300)
                  
                  // ìµœì¢… ìŠ¤í¬ë¡¤ ì²˜ë¦¬
                  setTimeout(() => {
                    scrollToBottomInstant()
                  }, 600)
                })
              }
            }, remainingTime)
          }
        }
      }

      loadChatHistory()
    } else {
      // chatIdë‚˜ sessionì´ ì—†ìœ¼ë©´ ìµœì†Œ ì‹œê°„ í›„ ë¡œë”© ì™„ë£Œ ì²˜ë¦¬
      const elapsedTime = Date.now() - skeletonStartTime
      const remainingTime = Math.max(0, minSkeletonDisplayTime - elapsedTime)
      
      setTimeout(() => {
        if (!isCancelled) {
          requestAnimationFrame(() => {
            setHistoryLoaded(true)
            setShowSkeleton(false)
          })
        }
      }, remainingTime)
    }

    // Cleanup function
    return () => {
      isCancelled = true
    }
  }, [chatId, session?.user?.email, isMobile])

  // Handle session status changes
  useEffect(() => {
    // Reset history load state when session changes
    if (!session?.user?.email) {
      setHistoryLoaded(false)
      setShowSkeleton(false)
      setMessages([])
    }
  }, [session?.user?.email])

  // Handle scroll on message change (also works when chat ID changes)
  const [isInitialLoad, setIsInitialLoad] = useState(true)
  
  useEffect(() => {
    if (messages.length > 0) {
      // ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ì„ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸
      const container = messagesContainerRef.current
      const userScrolled = (container as any)?.userScrolled?.() || false
      
      if (isInitialLoad) {
        // ì´ˆê¸° ë¡œë“œ ì‹œì—ëŠ” ì‚¬ìš©ì ìŠ¤í¬ë¡¤ ìƒíƒœì— ê´€ê³„ì—†ì´ ë§¨ ë°‘ìœ¼ë¡œ ì´ë™
        setTimeout(() => scrollToBottomInstant(), 100)
        setTimeout(() => scrollToBottomInstant(), 300)
        setTimeout(() => scrollToBottomInstant(), 600)
        setIsInitialLoad(false)
      } else if (!userScrolled || isStreaming) {
        // ì‚¬ìš©ìê°€ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ê±°ë‚˜ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¼ ë•Œë§Œ ìŠ¤í¬ë¡¤
        setTimeout(() => scrollToBottomSmooth(true), 100)
        // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ ì•„ë‹ ë•ŒëŠ” ì¶”ê°€ ìŠ¤í¬ë¡¤ ìµœì†Œí™”
        if (isStreaming) {
          setTimeout(() => scrollToBottomInstant(), 300)
          setTimeout(() => scrollToBottomInstant(), 600)
        }
      }
      
      // íŒ¨ë”© ì¡°ì •ì€ ì‚¬ìš©ì ìŠ¤í¬ë¡¤ ìƒíƒœì— ê´€ê³„ì—†ì´ ìˆ˜í–‰
      setTimeout(() => adjustDynamicPadding(), 200)
      
      // Clean up new message IDs after animation completes
      setTimeout(() => {
        setNewMessageIds(new Set())
      }, 1000)
    }
  }, [messages, isInitialLoad, adjustDynamicPadding, isStreaming])
  
  // Reset to initial load state when chatId changes
  useEffect(() => {
    setIsInitialLoad(true)
    const basePadding = isMobile !== undefined ? (isMobile ? 320 : 160) : 240
    setDynamicPadding(basePadding) // Reset padding too
  }, [chatId, isMobile])

  // Check if selected model supports multimodal input
  const supportsMultimodal = useMemo(() => {
    if (!selectedModel) return false
    
    if (selectedModel.type === 'agent') {
      // For agents, check both agent's supportsMultimodal and underlying model's supportsMultimodal
      const agentSupports = selectedModel.supportsMultimodal === true || selectedModel.supportsMultimodal === 1
      const modelSupports = selectedModel.modelSupportsMultimodal === true || selectedModel.modelSupportsMultimodal === 1
      return agentSupports || modelSupports
    } else if (selectedModel.type === 'model') {
      // For public models, check supportsMultimodal field
      return selectedModel.supportsMultimodal === true || selectedModel.supportsMultimodal === 1
    }
    
    return false
  }, [selectedModel])

  // Add scroll event listener - prevent auto scroll when user scrolls
  useEffect(() => {
    const container = messagesContainerRef.current
    if (!container) return

    let scrollTimeout: NodeJS.Timeout | null = null
    let userScrolled = false

    const handleScroll = () => {
      // ìŠ¤í¬ë¡¤ ì´ë²¤íŠ¸ ë””ë°”ìš´ì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
      if (scrollTimeout) {
        clearTimeout(scrollTimeout)
      }
      
      scrollTimeout = setTimeout(() => {
        // ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤í–ˆëŠ”ì§€ í™•ì¸
        if (!isScrollingToBottom.current) {
          const { scrollTop, scrollHeight, clientHeight } = container
          const isAtBottom = scrollHeight - scrollTop - clientHeight < 80
          
          // ì‚¬ìš©ìê°€ ìœ„ë¡œ ìŠ¤í¬ë¡¤í–ˆë‹¤ë©´ userScrolled í”Œë˜ê·¸ ì„¤ì •
          if (!isAtBottom) {
            userScrolled = true
            // ìŠ¤í¬ë¡¤ì´ ìƒë‹¨ìœ¼ë¡œ ì´ë™í•  ë•Œ ë Œë”ë§ ì•ˆì •ì„± í™•ë³´
            container.style.contentVisibility = 'auto'
          } else {
            // ì‚¬ìš©ìê°€ ë‹¤ì‹œ ë§¨ ë°‘ìœ¼ë¡œ ìŠ¤í¬ë¡¤í–ˆë‹¤ë©´ í”Œë˜ê·¸ í•´ì œ
            userScrolled = false
          }
        }
      }, 16) // 60fpsì— ë§ì¶° ë””ë°”ìš´ì‹±
    }

    container.addEventListener('scroll', handleScroll, { passive: true })
    
    // userScrolled ìƒíƒœë¥¼ containerì— ì €ì¥í•˜ì—¬ ë‹¤ë¥¸ í•¨ìˆ˜ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ í•¨
    ;(container as any).userScrolled = () => userScrolled
    
    return () => {
      container.removeEventListener('scroll', handleScroll)
      if (scrollTimeout) {
        clearTimeout(scrollTimeout)
      }
    }
  }, [])

  // Use ResizeObserver to detect content size changes and auto-scroll
  useEffect(() => {
    const container = messagesContainerRef.current
    if (!container) return

    const resizeObserver = new ResizeObserver((entries) => {
      for (const entry of entries) {
        // Don't auto-scroll if user has manually scrolled up
        const userScrolled = (container as any).userScrolled?.() || false
        if (userScrolled && !isStreaming) {
          // Prevent auto-scroll if not streaming and user has scrolled
          return
        }
        
        // Auto-scroll if user is near bottom when content size changes
        const { scrollTop, scrollHeight, clientHeight } = container
        const isNearBottom = scrollHeight - scrollTop - clientHeight < 200
        
        if (isNearBottom && !isScrollingToBottom.current) {
          // Short delay before scrolling (wait for DOM updates)
          setTimeout(() => {
            scrollToBottomInstant()
          }, 50)
        }
      }
    })

    // Observe message container
    resizeObserver.observe(container)
    
    // Also observe inner content container
    const innerContainer = container.querySelector('.max-w-full')
    if (innerContainer) {
      resizeObserver.observe(innerContainer)
    }

    return () => {
      resizeObserver.disconnect()
    }
  }, [isStreaming])

  // Clean up streaming on component unmount
  useEffect(() => {
    return () => {
      if (abortControllerRef.current) {
        abortControllerRef.current.abort()
      }
      streamingInProgress.current = false
      setIsStreaming(false)
    }
  }, [])

  // Move to bottom immediately without animation
  const scrollToBottomInstant = () => {
    if (messagesContainerRef.current) {
      const container = messagesContainerRef.current
      isScrollingToBottom.current = true
      
      // ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ í™•ì‹¤í•˜ê²Œ ë§¨ ë°‘ìœ¼ë¡œ ìŠ¤í¬ë¡¤
      const scrollToMax = () => {
        // ìŠ¤í¬ë¡¤ ë†’ì´ë¥¼ ë‹¤ì‹œ ê³„ì‚°í•˜ì—¬ ìµœì‹  ê°’ ì‚¬ìš©
        const maxScrollTop = container.scrollHeight - container.clientHeight
        container.scrollTop = Math.max(0, maxScrollTop)
        lastScrollHeight.current = container.scrollHeight
      }
      
      // ì¦‰ì‹œ ìŠ¤í¬ë¡¤
      scrollToMax()
      
      // DOM ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë‹¤ì¤‘ ì‹œë„
      requestAnimationFrame(() => {
        scrollToMax()
        
        requestAnimationFrame(() => {
          scrollToMax()
          
          // 100ms í›„ í•œ ë²ˆ ë”
          setTimeout(() => {
            scrollToMax()
            
            // 300ms í›„ ìµœì¢… í™•ì¸
            setTimeout(() => {
              scrollToMax()
              isScrollingToBottom.current = false
            }, 300)
          }, 100)
        })
      })
    }
  }

  // Move to bottom smoothly with animation
  const scrollToBottomSmooth = (force: boolean = false) => {
    if (messagesContainerRef.current && !isScrollingToBottom.current) {
      const container = messagesContainerRef.current
      const newScrollHeight = container.scrollHeight
      
      // Don't scroll if scroll height hasn't changed (ignore if force is true)
      if (!force && newScrollHeight <= lastScrollHeight.current + 10) {
        return
      }
      
      isScrollingToBottom.current = true
      lastScrollHeight.current = newScrollHeight
      
      // ì‹¤ì œ ìµœëŒ€ ìŠ¤í¬ë¡¤ ìœ„ì¹˜ ê³„ì‚°
      const maxScrollTop = Math.max(0, newScrollHeight - container.clientHeight)
      
      // ë¶€ë“œëŸ½ê²Œ ìŠ¤í¬ë¡¤
      container.scrollTo({
        top: maxScrollTop,
        behavior: 'smooth'
      })
      
      // ìŠ¤í¬ë¡¤ ì™„ë£Œ í›„ ì—¬ëŸ¬ ë²ˆ í™•ì¸
      setTimeout(() => {
        const currentMaxScrollTop = Math.max(0, container.scrollHeight - container.clientHeight)
        if (container.scrollTop < currentMaxScrollTop - 20) {
          container.scrollTop = currentMaxScrollTop
        }
        
        // í•œ ë²ˆ ë” í™•ì¸
        setTimeout(() => {
          const finalMaxScrollTop = Math.max(0, container.scrollHeight - container.clientHeight)
          if (container.scrollTop < finalMaxScrollTop - 20) {
            container.scrollTop = finalMaxScrollTop
          }
          isScrollingToBottom.current = false
        }, 300)
      }, 600) // ì• ë‹ˆë©”ì´ì…˜ ì™„ë£Œ ëŒ€ê¸°
    }
  }

  const adjustHeight = () => {
    // Use fixed height
  }

  const handleInputChange = useCallback((e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setInputValue(e.target.value)
    
    // Automatically adjust textarea height
    const target = e.target as HTMLTextAreaElement
    target.style.height = 'auto'
    target.style.height = Math.min(target.scrollHeight, window.innerHeight * 0.3) + 'px'
  }, [])

  const handleKeyUp = useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === "Shift") {
      setIsShiftPressed(false)
    }
  }, [])

  const handleCompositionStart = useCallback(() => {
    setIsComposing(true)
  }, [])

  const handleCompositionEnd = useCallback(() => {
    setIsComposing(false)
  }, [])

  const handleCopyMessage = useCallback((content: string, messageId: string) => {
    navigator.clipboard.writeText(content)
    setCopiedMessageId(messageId)
    // 2ì´ˆ í›„ ë³µì‚¬ ìƒíƒœ ì´ˆê¸°í™”
    setTimeout(() => {
      setCopiedMessageId(null)
    }, 2000)
  }, [])

  const handleLikeMessage = useCallback(async (messageId: string) => {
    const isCurrentlyLiked = likedMessages.has(messageId)
    const newRating = isCurrentlyLiked ? 0 : 1
    
    // ë‚™ê´€ì  ì—…ë°ì´íŠ¸
    setLikedMessages((prev) => {
      const newSet = new Set(prev)
      if (isCurrentlyLiked) {
        newSet.delete(messageId)
      } else {
        newSet.add(messageId)
        // ì¢‹ì•„ìš” ì‹œ ì‹«ì–´ìš” ì œê±°
        setDislikedMessages((prevDisliked) => {
          const newDislikedSet = new Set(prevDisliked)
          newDislikedSet.delete(messageId)
          return newDislikedSet
        })
      }
      return newSet
    })

    // API í˜¸ì¶œ
    try {
      const response = await fetch(`/api/chat/${chatId}/rating`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messageId,
          rating: newRating
        })
      })

      if (response.status === 401 || response.status === 404) {
        // ì¸ì¦ ì˜¤ë¥˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì—†ìŒ ì‹œ í™ˆí˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        router.push('/')
        return
      }

      if (!response.ok) {
        throw new Error('Failed to update rating')
      }
    } catch (error) {
      console.error('Error updating like:', error)
      // ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
      setLikedMessages((prev) => {
        const newSet = new Set(prev)
        if (isCurrentlyLiked) {
          newSet.add(messageId)
        } else {
          newSet.delete(messageId)
        }
        return newSet
      })
    }
  }, [chatId, likedMessages, router])

  const handleDislikeMessage = useCallback(async (messageId: string) => {
    const isCurrentlyDisliked = dislikedMessages.has(messageId)
    const newRating = isCurrentlyDisliked ? 0 : -1
    
    // ë‚™ê´€ì  ì—…ë°ì´íŠ¸
    setDislikedMessages((prev) => {
      const newSet = new Set(prev)
      if (isCurrentlyDisliked) {
        newSet.delete(messageId)
      } else {
        newSet.add(messageId)
        // ì‹«ì–´ìš” ì‹œ ì¢‹ì•„ìš” ì œê±°
        setLikedMessages((prevLiked) => {
          const newLikedSet = new Set(prevLiked)
          newLikedSet.delete(messageId)
          return newLikedSet
        })
      }
      return newSet
    })

    // API í˜¸ì¶œ
    try {
      const response = await fetch(`/api/chat/${chatId}/rating`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messageId,
          rating: newRating
        })
      })

      if (response.status === 401 || response.status === 404) {
        // ì¸ì¦ ì˜¤ë¥˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì—†ìŒ ì‹œ í™ˆí˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        router.push('/')
        return
      }

      if (!response.ok) {
        throw new Error('Failed to update rating')
      }
    } catch (error) {
      console.error('Error updating dislike:', error)
      // ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
      setDislikedMessages((prev) => {
        const newSet = new Set(prev)
        if (isCurrentlyDisliked) {
          newSet.add(messageId)
        } else {
          newSet.delete(messageId)
        }
        return newSet
      })
    }
  }, [chatId, dislikedMessages, router])

  const handleEditMessage = useCallback((messageId: string, content: string) => {
    setEditingMessageId(messageId)
    setEditingContent(content)
    setSelectedMessageId(null)
  }, [])

  const handleSaveEdit = (messageId: string) => {
    // ë©”ì‹œì§€ ë‚´ìš© ì—…ë°ì´íŠ¸
    const updatedMessages = messages.map((msg) => 
      msg.id === messageId ? { ...msg, content: editingContent } : msg
    )
    setMessages(updatedMessages)
    
    // í¸ì§‘ ìƒíƒœ ì´ˆê¸°í™”
    setEditingMessageId(null)
    const savedContent = editingContent
    setEditingContent("")

    // í¸ì§‘ëœ ì‚¬ìš©ì ë©”ì‹œì§€ì¸ ê²½ìš° í•´ë‹¹ ë©”ì‹œì§€ ì´í›„ ëª¨ë“  ë©”ì‹œì§€ ì‚­ì œí•˜ê³  ì¬ìƒì„±
    const messageIndex = messages.findIndex((msg) => msg.id === messageId)
    const editedMessage = messages[messageIndex]
    
    if (editedMessage && editedMessage.role === "user" && selectedModel && chatId && session?.user?.email) {
      // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
      if (isStreaming) {
        handleAbort()
      }
      
      // í•´ë‹¹ ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•´ ì¬ìƒì„± ìƒíƒœ ì„¤ì •
      setRegeneratingMessageId(messageId)
      
      // í•´ë‹¹ ì‚¬ìš©ì ë©”ì‹œì§€ ì´í›„ì˜ ëª¨ë“  ë©”ì‹œì§€ ì œê±° (í¸ì§‘ëœ ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ìœ ì§€)
      setTimeout(() => {
        setMessages(prev => prev.slice(0, messageIndex + 1))
        
        // ìŠ¤í¬ë¡¤ì„ í˜„ì¬ ìœ„ì¹˜ë¡œ ì´ë™
        setTimeout(() => scrollToBottomSmooth(), 100)

        // í¸ì§‘ëœ ë‚´ìš©ìœ¼ë¡œ AI ì¬ìƒì„±
        setTimeout(() => {
          // ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì´ˆê¸°í™”
          streamingInProgress.current = false
          sessionStorage.removeItem(`lastMessage_${chatId}`)
          lastSubmittedMessage.current = null
          lastSubmittedTime.current = 0
          
          sendMessageToAI(savedContent, {
            id: selectedModel.id,
            type: selectedModel.type
          }, true)
        }, 300)
      }, 100) // ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ í›„ ì ì‹œ ëŒ€ê¸°
    }
  }

  const handleCancelEdit = useCallback(() => {
    setEditingMessageId(null)
    setEditingContent("")
  }, [])

  const handleRegenerateResponse = (messageId: string) => {
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
    if (isStreaming) {
      handleAbort()
    }
    
    // í•´ë‹¹ AI ì‘ë‹µ ë©”ì‹œì§€ì™€ ê·¸ ì´í›„ì˜ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  ë‹¤ì‹œ ìƒì„±
    const messageIndex = messages.findIndex((msg) => msg.id === messageId)
    if (messageIndex > 0 && selectedModel && chatId && session?.user?.email) {
      const previousUserMessage = messages[messageIndex - 1]
      if (previousUserMessage.role === "user") {
        // í•´ë‹¹ ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•´ ì¬ìƒì„± ìƒíƒœ ì„¤ì •
        setRegeneratingMessageId(previousUserMessage.id)
        
        // í•´ë‹¹ AI ì‘ë‹µ ë©”ì‹œì§€ë¶€í„° ëª¨ë“  ë©”ì‹œì§€ ì œê±° (ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ìœ ì§€)
        setMessages(messages.slice(0, messageIndex))
        
        // ìŠ¤í¬ë¡¤ì„ í˜„ì¬ ìœ„ì¹˜ë¡œ ì´ë™
        setTimeout(() => scrollToBottomSmooth(), 100)

        // ì¬ìƒì„±ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™” ë° AI ìš”ì²­
        setTimeout(() => {
          // ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì´ˆê¸°í™”
          streamingInProgress.current = false
          sessionStorage.removeItem(`lastMessage_${chatId}`)
          lastSubmittedMessage.current = null
          lastSubmittedTime.current = 0
          
          sendMessageToAI(previousUserMessage.content, {
            id: selectedModel.id,
            type: selectedModel.type
          }, true)
        }, 300) // ì¤‘ë‹¨ ì²˜ë¦¬ ì™„ë£Œë¥¼ ìœ„í•´ ì§§ì€ ì§€ì—°
      }
    }
  }

  const handleRegenerateFromUserMessage = async (messageId: string) => {
    console.log('=== handleRegenerateFromUserMessage called ===')
    console.log('messageId:', messageId)
    console.log('isStreaming:', isStreaming)
    console.log('regeneratingMessageId:', regeneratingMessageId)
    
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
    if (isStreaming) {
      handleAbort()
    }
    
    // í•´ë‹¹ ì‚¬ìš©ì ë©”ì‹œì§€ë¶€í„° í•˜ìœ„ ëª¨ë“  ë©”ì‹œì§€ ì œê±°í•˜ê³  ë‹¤ì‹œ ìƒì„±
    const messageIndex = messages.findIndex((msg) => msg.id === messageId)
    if (messageIndex >= 0 && selectedModel && chatId && session?.user?.email) {
      const userMessage = messages[messageIndex]
      if (userMessage.role === "user") {
        // í•´ë‹¹ ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•´ ì¬ìƒì„± ìƒíƒœ ì„¤ì •
        console.log('Setting regeneratingMessageId to:', messageId)
        setRegeneratingMessageId(messageId)
        
        // ì‚¬ìš©ì ë©”ì‹œì§€ ë‹¤ìŒë¶€í„°ì˜ ëª¨ë“  ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        const nextMessageIndex = messageIndex + 1
        if (nextMessageIndex < messages.length) {
          const nextMessage = messages[nextMessageIndex]
          
          try {
            console.log('=== Attempting to delete messages from database ===');
            console.log('nextMessage.id:', nextMessage.id);
            console.log('chatId:', chatId);
            console.log('session.user.email:', session.user.email);
            
            // ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ë©”ì‹œì§€ë¶€í„° ì´í›„ ëª¨ë“  ë©”ì‹œì§€ ì‚­ì œ
            const response = await fetch(`/api/chat/${chatId}?userId=${session.user.email}&fromMessageId=${nextMessage.id}`, {
              method: 'DELETE'
            })
            
            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              console.error('Delete API response not ok:', response.status, errorData);
              throw new Error(`Failed to delete messages from database: ${response.status} ${errorData.error || response.statusText}`);
            }
            
            const deleteResult = await response.json();
            console.log('Delete operation successful:', deleteResult);
            
            if (deleteResult.success) {
              console.log(`Successfully deleted ${deleteResult.deletedCount} messages from database`);
              console.log(`Remaining messages in database: ${deleteResult.remainingCount}`);
              
              // ì‚­ì œ ì‘ì—…ì´ ì™„ë£Œëœ í›„ ì‹¤ì œë¡œ ë©”ì‹œì§€ê°€ ì‚­ì œë˜ì—ˆëŠ”ì§€ ê²€ì¦
              if (deleteResult.deletedCount > 0) {
                console.log('=== Verifying deletion by reloading chat history ===');
                
                // ì ì‹œ í›„ ì±„íŒ… ê¸°ë¡ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ì‚­ì œê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                setTimeout(async () => {
                  try {
                    const verifyResponse = await fetch(`/api/chat/${chatId}`);
                    if (verifyResponse.ok) {
                      const verifyData = await verifyResponse.json();
                      const currentMessages = verifyData.messages || [];
                      
                      console.log('Verification: Current messages in database:', currentMessages.length);
                      
                      // ì‚­ì œëœ ë©”ì‹œì§€ê°€ ì—¬ì „íˆ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                      const deletedMessageStillExists = currentMessages.some((msg: any) => msg.id === nextMessage.id);
                      
                      if (deletedMessageStillExists) {
                        console.error('ERROR: Deleted message still exists in database!');
                        console.error('This may cause the regeneration issue on page refresh');
                      } else {
                        console.log('âœ“ Verification successful: Messages properly deleted from database');
                      }
                    }
                  } catch (verifyError) {
                    console.error('Failed to verify deletion:', verifyError);
                  }
                }, 1000);
              }
            } else {
              console.warn('Delete operation reported failure:', deleteResult);
            }
          } catch (error) {
            console.error('Error deleting messages from database:', error);
            
            // ì‚¬ìš©ìì—ê²Œ ì—ëŸ¬ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
            if (error instanceof Error && error.message.includes('Failed to delete messages')) {
              console.warn('Database deletion failed, but continuing with UI update');
              // ì—¬ê¸°ì„œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ì„ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
              // alert('ì¼ë¶€ ë©”ì‹œì§€ ì‚­ì œì— ì‹¤íŒ¨í–ˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.');
            }
            
            // ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨í•´ë„ UIì—ì„œëŠ” ì§„í–‰
            console.log('Continuing with regeneration despite database deletion error');
          }
        } else {
          console.log('No messages to delete after current user message');
        }
        
        // í•´ë‹¹ ì‚¬ìš©ì ë©”ì‹œì§€ ì´í›„ì˜ ëª¨ë“  ë©”ì‹œì§€ ì œê±° (ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ìœ ì§€)
        setMessages(messages.slice(0, messageIndex + 1))
        
        // ìŠ¤í¬ë¡¤ì„ í˜„ì¬ ìœ„ì¹˜ë¡œ ì´ë™
        setTimeout(() => scrollToBottomSmooth(), 100)

        // ì¬ìƒì„±ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™” ë° AI ìš”ì²­
        setTimeout(async () => {
          console.log('=== Starting regeneration process ===')
          console.log('selectedModel:', selectedModel)
          console.log('chatId:', chatId)
          console.log('session?.user?.email:', session?.user?.email)
          
          // ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì´ˆê¸°í™”
          streamingInProgress.current = false
          sessionStorage.removeItem(`lastMessage_${chatId}`)
          lastSubmittedMessage.current = null
          lastSubmittedTime.current = 0
          
          // ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
          let messageContent = userMessage.content
          let imagesToSend: File[] = []
          
          try {
            // JSON í˜•íƒœë¡œ ì €ì¥ëœ ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
            const parsed = JSON.parse(userMessage.content)
            if (parsed.hasImages && parsed.images && Array.isArray(parsed.images)) {
              messageContent = parsed.text || ''
              // Base64 ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
              imagesToSend = await Promise.all(
                parsed.images.map(async (imageInfo: any) => {
                  if (imageInfo.data) {
                    // Base64 ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
                    const response = await fetch(imageInfo.data)
                    const blob = await response.blob()
                    // Blobì„ File ê°ì²´ë¡œ ë³€í™˜
                    return new File([blob], imageInfo.name || 'image.png', { 
                      type: imageInfo.mimeType || 'image/png' 
                    })
                  }
                  return null
                })
              ).then(files => files.filter(file => file !== null) as File[])
            }
          } catch (e) {
            // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            messageContent = userMessage.content
          }
          
          console.log('=== Calling sendMessageToAI ===')
          console.log('messageContent:', messageContent)
          console.log('agentInfo:', { id: selectedModel.id, type: selectedModel.type })
          console.log('isRegeneration:', true)
          console.log('imagesToSend:', imagesToSend)
          
          try {
            await sendMessageToAI(messageContent, {
              id: selectedModel.id,
              type: selectedModel.type
            }, true, imagesToSend)
            console.log('=== Regeneration sendMessageToAI completed ===')
          } catch (error) {
            console.error('Error in sendMessageToAI during regeneration:', error)
            // ì¬ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ ìƒíƒœ ë¦¬ì…‹
            console.log('Resetting regeneration state due to error in regeneration')
            setRegeneratingMessageId(null)
            setIsStreaming(false)
            streamingInProgress.current = false
          }
        }, 300) // ì¤‘ë‹¨ ì²˜ë¦¬ ì™„ë£Œë¥¼ ìœ„í•´ ì§§ì€ ì§€ì—°
      }
    }
  }

  const handleSubmit = useCallback(async () => {
    // ì´ë¯¸ ì „ì†¡ ì¤‘ì¸ ê²½ìš° ì°¨ë‹¨ (ì´ì¤‘ ì²´í¬)
    if (isSubmitting || isSubmittingRef.current) {
      console.log('Already submitting, preventing duplicate')
      return
    }
    
    // ì¤‘ë³µ ë©”ì‹œì§€ ê²€ì‚¬ (ê°™ì€ ë©”ì‹œì§€ê°€ 500ms ì´ë‚´ì— ì „ì†¡ë˜ëŠ” ê²½ìš°)
    const currentTime = Date.now()
    const messageToCheck = inputValue.trim() || 'IMAGE_ONLY'
    
    if (lastSubmittedMessage.current === messageToCheck && 
        currentTime - lastSubmittedTime.current < 500) {
      console.log('Duplicate message detected, preventing submission')
      return
    }
    
    // ë¹ˆ ë©”ì‹œì§€ ì²´í¬ (í…ìŠ¤íŠ¸ë„ ì—†ê³  ì´ë¯¸ì§€ë„ ì—†ëŠ” ê²½ìš°)
    if (!inputValue.trim() && uploadedImages.length === 0) {
      console.log('Empty message, preventing submission')
      return
    }
    
    // ì „ì†¡ ì‹œì‘ í”Œë˜ê·¸ ì„¤ì •
    isSubmittingRef.current = true
    
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
    if (isStreaming) {
      handleAbort()
    }
    
    if ((inputValue.trim() || uploadedImages.length > 0) && selectedModel && chatId && session?.user?.email) {
      try {
        // ì „ì†¡ ì¤‘ í”Œë˜ê·¸ ì„¤ì •
        setIsSubmitting(true)
        
        // ìƒˆ ë©”ì‹œì§€ ì „ì†¡ ì‹œ ì¬ìƒì„± ìƒíƒœ ë¦¬ì…‹
        console.log('New message submission - resetting regeneration state')
        setRegeneratingMessageId(null)
        
        // ì¤‘ë³µ ë°©ì§€ ì •ë³´ ì—…ë°ì´íŠ¸
        lastSubmittedMessage.current = messageToCheck
        lastSubmittedTime.current = currentTime
      
      // ì „ì†¡í•  ì´ë¯¸ì§€ì™€ ë©”ì‹œì§€ ì½˜í…ì¸  ì¤€ë¹„
      const imagesToSend = [...uploadedImages]
      const messageContent = inputValue
      
      // ì‚¬ìš©ì ë©”ì‹œì§€ ì½˜í…ì¸  ìƒì„± (ì´ë¯¸ì§€ ì •ë³´ í¬í•¨)
      let userMessageContent = inputValue || ''
      
      // ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° JSON í˜•íƒœë¡œ ì €ì¥ (UserRequestì—ì„œ íŒŒì‹±í•˜ì—¬ í‘œì‹œ)
      if (imagesToSend.length > 0) {
        const imageInfos = await Promise.all(
          imagesToSend.map(async (image) => {
            // ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œë¥¼ ìœ„í•´ base64 ë°ì´í„°ë„ í¬í•¨
            const reader = new FileReader()
            const base64 = await new Promise<string>((resolve) => {
              reader.onload = (e) => resolve(e.target?.result as string)
              reader.readAsDataURL(image)
            })
            
            return {
              type: 'image',
              name: image.name,
              size: image.size,
              mimeType: image.type,
              data: base64
            }
          })
        )
        
        userMessageContent = JSON.stringify({
          text: inputValue || '',
          images: imageInfos,
          hasImages: true
        })
      }

      // ë©”ì‹œì§€ ì¶”ê°€ (ì´ë¯¸ì§€ ì •ë³´ í¬í•¨)
      const newUserMessage: Message = {
        id: generateUniqueId("user"),
        role: "user",
        content: userMessageContent,
        timestamp: new Date(),
      }

      // ìƒˆ ë©”ì‹œì§€ ID ì¶”ê°€
      setNewMessageIds(prev => new Set([...prev, newUserMessage.id]))
      setMessages([...messages, newUserMessage])
      
      // ì…ë ¥ ìƒíƒœ ì´ˆê¸°í™”
      setInputValue("")
      setUploadedImages([]) // ì´ë¯¸ì§€ ìƒíƒœ ì´ˆê¸°í™”
      
      // ChatInputì˜ ì´ë¯¸ì§€ë„ ì´ˆê¸°í™”
      setClearImagesTrigger(prev => !prev)
      
      // í…ìŠ¤íŠ¸ ì…ë ¥ì°½ ê°•ì œ ì´ˆê¸°í™” (í•œê¸€ IME ì¡°í•© ì¤‘ì¸ ê¸€ì ì œê±°)
      // IME ì¡°í•© ì™„ë£Œë¥¼ ìœ„í•´ ì•½ê°„ì˜ ì§€ì—° í›„ ì´ˆê¸°í™”
      setTimeout(() => {
        if (textareaRef.current) {
          textareaRef.current.value = ""
          textareaRef.current.style.height = "auto"
          textareaRef.current.style.height = "52px"
          
          // React ìƒíƒœì™€ ë™ê¸°í™”
          setInputValue("")
        }
      }, 0)
      
      // ë©”ì‹œì§€ ì¶”ê°€ í›„ ìŠ¤í¬ë¡¤ (ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤í•˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ)
      const container = messagesContainerRef.current
      const userScrolled = (container as any)?.userScrolled?.() || false
      
      if (!userScrolled) {
        scrollToBottomSmooth()
      }

      // ìŠ¤íŠ¸ë¦¬ë°ì´ ì¤‘ë‹¨ë˜ì—ˆë‹¤ë©´ ì ì‹œ ëŒ€ê¸° í›„ ìƒˆ ë©”ì‹œì§€ ì „ì†¡
      const sendMessage = () => {
        sendMessageToAI(messageContent, {
          id: selectedModel.id,
          type: selectedModel.type
        }, false, imagesToSend).finally(() => {
          // ì „ì†¡ ì™„ë£Œ í›„ í”Œë˜ê·¸ í•´ì œ
          setIsSubmitting(false)
          isSubmittingRef.current = false
        })
      }
      
        if (isStreaming) {
          // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì²˜ë¦¬ ì™„ë£Œë¥¼ ìœ„í•´ ì§§ì€ ì§€ì—° í›„ ì „ì†¡
          setTimeout(sendMessage, 100)
        } else {
          // ì¦‰ì‹œ ì „ì†¡
          sendMessage()
        }
      } catch (error) {
        console.error('Error in handleSubmit:', error)
        // ì—ëŸ¬ ë°œìƒ ì‹œ í”Œë˜ê·¸ í•´ì œ
        setIsSubmitting(false)
        isSubmittingRef.current = false
      }
    }
  }, [inputValue, uploadedImages, messages, selectedModel, chatId, session?.user?.email, isStreaming, isSubmitting, generateUniqueId, scrollToBottomSmooth, sendMessageToAI, handleAbort])

  const handleKeyDown = useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === "Shift") {
      setIsShiftPressed(true)
    }

    if (e.key === "Enter") {
      if (e.shiftKey) {
        // Allow line break with Shift + Enter (default behavior)
        return
      } else {
        // Submit on Enter only
        e.preventDefault()
        
        // Check if IME composition is in progress
        if (e.nativeEvent.isComposing || isComposing) {
          // Wait if composition is in progress
          return
        }
        
        // Execute immediately (removed setTimeout to prevent duplicate execution)
        handleSubmit()
      }
    }
  }, [handleSubmit, isComposing])

  // ë©”ì‹œì§€ ë Œë”ë§ì„ ì¡°ê±´ë¶€ ë Œë”ë§ ë°–ì—ì„œ ì •ì˜í•˜ì—¬ Hook ìˆœì„œ ìœ ì§€
  const renderedMessages = useMemo(() => {
    console.log('=== Rendering messages ===')
    console.log('messages.length:', messages.length)
    console.log('historyLoaded:', historyLoaded)
    console.log('showSkeleton:', showSkeleton)
    console.log('regeneratingMessageId:', regeneratingMessageId)
    console.log('isStreaming:', isStreaming)
    
    return messages.map((message, index) => (
      <MessageWrapper
        key={`${message.id}-${forceUpdateCounter}-${regeneratingMessageId || 'none'}`}
        message={message}
        isNewMessage={newMessageIds.has(message.id)}
        copiedMessageId={copiedMessageId}
        likedMessages={likedMessages}
        dislikedMessages={dislikedMessages}
        isStreaming={isStreaming}
        editingMessageId={editingMessageId}
        editingContent={editingContent}
        regeneratingMessageId={regeneratingMessageId}
        streamingMessageId={streamingMessageId}
        onCopy={handleCopyMessage}
        onLike={handleLikeMessage}
        onDislike={handleDislikeMessage}
        onRegenerate={handleRegenerateResponse}
        onEdit={handleEditMessage}
        onSave={handleSaveEdit}
        onCancel={handleCancelEdit}
        onRegenerateFromUser={handleRegenerateFromUserMessage}
        setEditingContent={setEditingContent}
      />
    ))
  }, [messages, newMessageIds, copiedMessageId, likedMessages, dislikedMessages, isStreaming, editingMessageId, editingContent, regeneratingMessageId, streamingMessageId, forceUpdateCounter]
  )

  // ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ë¦¬ë‹¤ì´ë ‰íŠ¸
  if (sessionStatus === "unauthenticated") {
    router.push('/auth')
    return null
  }

  return (
    <>
      {/* ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ */}
      <div className="flex-1 flex flex-col px-3 sm:px-0 relative overflow-hidden">
        <div 
          ref={messagesContainerRef}
          className="messages-container flex-1 overflow-y-auto p-3 sm:p-4 md:p-6 transition-all duration-200 ease-out mobile-scroll touch-scroll"
          style={{ 
            scrollBehavior: 'smooth',
            paddingBottom: `${dynamicPadding}px`,
            overflowAnchor: 'none'
          }}
        >
          <div className="sm:px-3 max-w-full sm:max-w-2xl md:max-w-3xl lg:max-w-4xl mx-auto">
            {(() => {
              console.log('=== Render condition check ===')
              console.log('!historyLoaded && showSkeleton:', !historyLoaded && showSkeleton)
              console.log('!historyLoaded && !showSkeleton:', !historyLoaded && !showSkeleton)
              console.log('else (should render messages):', historyLoaded)
              console.log('renderedMessages length:', renderedMessages.length)
              
              if (!historyLoaded && showSkeleton) {
                console.log('Rendering skeleton')
                return <ChatMessageSkeleton />
              } else if (!historyLoaded && !showSkeleton) {
                console.log('Rendering empty div')
                return <div></div>
              } else {
                console.log('Rendering messages')
                return renderedMessages
              }
            })()}
            <div ref={messagesEndRef} className="h-4" />
          </div>
        </div>

        {/* ì…ë ¥ ì»¨í…Œì´ë„ˆ - ë‹¨ ê³ ì • */}
          <ChatInput
            inputValue={inputValue}
            textareaRef={textareaRef}
            isGlobeActive={isGlobeActive}
            isDeepResearchActive={isDeepResearchActive}
            isStreaming={isStreaming}
            isSubmitting={isSubmitting}
            handleInputChange={handleInputChange}
            handleKeyDown={handleKeyDown}
            handleKeyUp={handleKeyUp}
            handleCompositionStart={handleCompositionStart}
            handleCompositionEnd={handleCompositionEnd}
            handleSubmit={handleSubmit}
            handleAbort={handleAbort}
            setIsGlobeActive={setIsGlobeActive}
            setIsDeepResearchActive={setIsDeepResearchActive}
            onImageUpload={handleImageUpload}
            clearImages={clearImagesTrigger}
            supportsMultimodal={supportsMultimodal}
            selectedAgent={selectedModel?.type === 'agent' ? selectedModel : null}
          />
      </div>
    </>
  )
}
