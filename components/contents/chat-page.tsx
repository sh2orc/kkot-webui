"use client"

import type React from "react"

import { useRef, useState, useEffect, useCallback, useMemo, memo } from "react"
import { useRouter, useSearchParams } from "next/navigation"
import { useSession } from "next-auth/react"
import { LlmResponse } from "@/components/chat/llm-response"
import { UserRequest } from "@/components/chat/user-request"
import { ChatInput } from "@/components/chat/chat-input"
import { useTranslation } from "@/lib/i18n"
import { useModel } from "@/components/providers/model-provider"
import { Skeleton } from "@/components/ui/skeleton"
import { useIsMobile } from "@/hooks/use-mobile"
import { toast } from "sonner"

interface Message {
  id: string
  role: "user" | "assistant"
  content: string
  timestamp: Date
  isDeepResearch?: boolean
  deepResearchStepType?: 'step' | 'synthesis' | 'final'
  isDeepResearchComplete?: boolean
  hasDeepResearchError?: boolean
  deepResearchStepInfo?: Record<string, any>
}

interface ChatPageProps {
  chatId?: string
}

// Memoized message wrapper component
const MessageWrapper = memo(({ 
  message, 
  isNewMessage, 
  copiedMessageId, 
  likedMessages, 
  dislikedMessages, 
  isStreaming, 
  editingMessageId, 
  editingContent, 
  regeneratingMessageId,
  streamingMessageId,
  onCopy, 
  onLike, 
  onDislike, 
  onRegenerate, 
  onEdit, 
  onSave, 
  onCancel, 
  onRegenerateFromUser, 
  setEditingContent 
}: {
  message: Message
  isNewMessage: boolean
  copiedMessageId: string | null
  likedMessages: Set<string>
  dislikedMessages: Set<string>
  isStreaming: boolean
  editingMessageId: string | null
  editingContent: string
  regeneratingMessageId: string | null
  streamingMessageId: string | null
  onCopy: (content: string, messageId: string) => void
  onLike: (messageId: string) => void
  onDislike: (messageId: string) => void
  onRegenerate: (messageId: string) => void
  onEdit: (messageId: string, content: string) => void
  onSave: (messageId: string) => void
  onCancel: () => void
  onRegenerateFromUser: (messageId: string) => void
  setEditingContent: (content: string) => void
}) => {
  return (
    <div 
      className={`message-item mb-6 ${isNewMessage ? 'message-enter' : ''} ${message.role === "user" ? "flex justify-end" : ""}`}
    >
      {message.role === "assistant" && (
        <LlmResponse
          id={message.id}
          content={message.content}
          timestamp={message.timestamp}
          onCopy={onCopy}
          onLike={onLike}
          onDislike={onDislike}
          onRegenerate={onRegenerate}
          copiedMessageId={copiedMessageId}
          likedMessages={likedMessages}
          dislikedMessages={dislikedMessages}
          isStreaming={isStreaming && streamingMessageId === message.id}
          isDeepResearch={message.isDeepResearch}
          deepResearchStepType={message.deepResearchStepType}
          isDeepResearchComplete={message.isDeepResearchComplete}
          hasDeepResearchError={message.hasDeepResearchError}
          deepResearchStepInfo={message.deepResearchStepInfo}
        />
      )}

      {message.role === "user" && (
        <UserRequest
          id={message.id}
          content={message.content}
          timestamp={message.timestamp}
          onCopy={onCopy}
          onEdit={onEdit}
          onSave={onSave}
          onCancel={onCancel}
          onRegenerate={onRegenerateFromUser}
          editingMessageId={editingMessageId}
          editingContent={editingContent}
          setEditingContent={setEditingContent}
          copiedMessageId={copiedMessageId}
          isStreaming={isStreaming}
          regeneratingMessageId={regeneratingMessageId}
        />
      )}
    </div>
  )
}, (prevProps, nextProps) => {
  // Only rerender if message content hasn't changed and only state related to this message has changed
  const message = prevProps.message
  const nextMessage = nextProps.message
  
  // Message content has changed, rerender
  if (message.id !== nextMessage.id || message.content !== nextMessage.content) {
    return false
  }
  
  // Current message is streaming, rerender
  if (nextProps.streamingMessageId === message.id) {
    return false
  }
  
  // Current message is being edited, rerender
  if (nextProps.editingMessageId === message.id) {
    return false
  }
  
  // Current message is being regenerated or regeneration state changed, rerender
  if (nextProps.regeneratingMessageId === message.id || 
      prevProps.regeneratingMessageId === message.id) {
    return false
  }
  
  // Current message has been copied, rerender
  if (nextProps.copiedMessageId === message.id) {
    return false
  }
  
  // Current message is new, rerender
  if (nextProps.isNewMessage !== prevProps.isNewMessage) {
    return false
  }
  
  // Like/dislike state has changed, rerender
  if (nextProps.likedMessages.has(message.id) !== prevProps.likedMessages.has(message.id) ||
      nextProps.dislikedMessages.has(message.id) !== prevProps.dislikedMessages.has(message.id)) {
    return false
  }
  
  // Don't rerender in other cases
  return true
})

// Chat message skeleton component
const ChatMessageSkeleton = () => {
  return (
    <div className="space-y-6 animate-pulse">
      {/* First AI response skeleton */}
      <div className="flex justify-start mb-6">
        <div className="w-full max-w-[90%] space-y-2">
          <div className="flex items-center space-x-2">
            <div className="h-3 w-3 bg-gray-300 dark:bg-gray-600 rounded-full animate-skeleton-pulse"></div>
            <div className="h-3 w-16 bg-gray-300 dark:bg-gray-600 rounded animate-skeleton-pulse" style={{animationDelay: '0.1s'}}></div>
          </div>
          <div className="space-y-2">
            <div className="h-4 w-full bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.2s'}}></div>
            <div className="h-4 w-[95%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.3s'}}></div>
            <div className="h-4 w-[85%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.4s'}}></div>
            <div className="h-4 w-[92%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.5s'}}></div>
            <div className="h-4 w-[78%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.6s'}}></div>
          </div>
        </div>
      </div>

      {/* Second AI response skeleton */}
      <div className="flex justify-start mb-6">
        <div className="w-full max-w-[90%] space-y-2">
          <div className="flex items-center space-x-2">
            <div className="h-3 w-3 bg-gray-300 dark:bg-gray-600 rounded-full animate-skeleton-pulse" style={{animationDelay: '0.7s'}}></div>
            <div className="h-3 w-16 bg-gray-300 dark:bg-gray-600 rounded animate-skeleton-pulse" style={{animationDelay: '0.8s'}}></div>
          </div>
          <div className="space-y-2">
            <div className="h-4 w-[90%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '0.9s'}}></div>
            <div className="h-4 w-full bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.0s'}}></div>
            <div className="h-4 w-[87%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.1s'}}></div>
            <div className="h-4 w-[65%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.2s'}}></div>
          </div>
        </div>
      </div>

      {/* Third AI response skeleton */}
      <div className="flex justify-start mb-6">
        <div className="w-full max-w-[90%] space-y-2">
          <div className="flex items-center space-x-2">
            <div className="h-3 w-3 bg-gray-300 dark:bg-gray-600 rounded-full animate-skeleton-pulse" style={{animationDelay: '1.3s'}}></div>
            <div className="h-3 w-16 bg-gray-300 dark:bg-gray-600 rounded animate-skeleton-pulse" style={{animationDelay: '1.4s'}}></div>
          </div>
          <div className="space-y-2">
            <div className="h-4 w-[82%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.5s'}}></div>
            <div className="h-4 w-[96%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.6s'}}></div>
            <div className="h-4 w-full bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.7s'}}></div>
            <div className="h-4 w-[89%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.8s'}}></div>
            <div className="h-4 w-[75%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '1.9s'}}></div>
            <div className="h-4 w-[91%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '2.0s'}}></div>
            <div className="h-4 w-[68%] bg-gray-200 dark:bg-gray-700 rounded animate-skeleton-pulse" style={{animationDelay: '2.1s'}}></div>
          </div>
        </div>
      </div>
    </div>
  )
}

export default function ChatPage({ chatId }: ChatPageProps) {
  const router = useRouter()
  const searchParams = useSearchParams()
  const { data: session, status: sessionStatus } = useSession()
  const { lang } = useTranslation('chat')
  const { selectedModel } = useModel()
  const isMobile = useIsMobile()
  const textareaRef = useRef<HTMLTextAreaElement>(null)
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const messagesContainerRef = useRef<HTMLDivElement>(null)
  const [inputValue, setInputValue] = useState("")
  const [isGlobeActive, setIsGlobeActive] = useState(false)
  const [isDeepResearchActive, setIsDeepResearchActive] = useState(false)
  const [isShiftPressed, setIsShiftPressed] = useState(false)
  const [messages, setMessages] = useState<Message[]>([])
  const [selectedMessageId, setSelectedMessageId] = useState<string | null>(null)
  const [editingMessageId, setEditingMessageId] = useState<string | null>(null)
  const [editingContent, setEditingContent] = useState("")

  const [copiedMessageId, setCopiedMessageId] = useState<string | null>(null)
  const [likedMessages, setLikedMessages] = useState<Set<string>>(new Set())
  const [dislikedMessages, setDislikedMessages] = useState<Set<string>>(new Set())
  const [historyLoaded, setHistoryLoaded] = useState(false)
  const [showSkeleton, setShowSkeleton] = useState(false)
  const [isStreaming, setIsStreaming] = useState(false)
  const [regeneratingMessageId, setRegeneratingMessageId] = useState<string | null>(null)
  const [forceUpdateCounter, setForceUpdateCounter] = useState(0)
  
  // Debug: ìž¬ìƒì„± ìƒíƒœ ë³€ê²½ ì „ì—­ ì¶”ì 
  useEffect(() => {
    console.log('=== Global regeneratingMessageId changed ===')
    console.log('New regeneratingMessageId:', regeneratingMessageId)
    console.log('Current isStreaming:', isStreaming)
    
    // ìž¬ìƒì„± ìƒíƒœê°€ ë³€ê²½ë  ë•Œ ê°•ì œ ë¦¬ë Œë”ë§ì„ ìœ„í•œ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
    console.log('=== Force re-render trigger ===')
    setForceUpdateCounter(prev => prev + 1)
  }, [regeneratingMessageId])
  const [newMessageIds, setNewMessageIds] = useState<Set<string>>(new Set())
  const [streamingMessageId, setStreamingMessageId] = useState<string | null>(null)
  const [uploadedImages, setUploadedImages] = useState<File[]>([])
  const [isSubmitting, setIsSubmitting] = useState(false)
  const [isComposing, setIsComposing] = useState(false)
  const [clearImagesTrigger, setClearImagesTrigger] = useState(false)
  const [deepResearchPlannedSteps, setDeepResearchPlannedSteps] = useState<Array<{ title: string, type: string }>>([])
  // Set safer initial value
  const [dynamicPadding, setDynamicPadding] = useState(() => {
    // Use default value on server side, detect screen size on client
    if (typeof window === 'undefined') return 240
    return window.innerWidth < 768 ? 320 : 160
  })
  
  // Ref to prevent React Strict Mode duplicate execution
  const streamingInProgress = useRef(false)
  const abortControllerRef = useRef<AbortController | null>(null)
  const isScrollingToBottom = useRef(false)
  const lastScrollHeight = useRef(0)
  const lastSubmittedMessage = useRef<string | null>(null)
  const lastSubmittedTime = useRef<number>(0)
  const isSubmittingRef = useRef(false) // ì¶”ê°€ì ì¸ ì¤‘ë³µ ë°©ì§€

  // Reset padding when isMobile changes
  useEffect(() => {
    if (isMobile !== undefined) {
      const basePadding = isMobile ? 320 : 160
      setDynamicPadding(basePadding)
    }
  }, [isMobile])

  // Detect message container height and adjust dynamic padding
  const adjustDynamicPadding = useCallback(() => {
    if (messagesContainerRef.current) {
      const container = messagesContainerRef.current
      const containerHeight = container.clientHeight
      const scrollHeight = container.scrollHeight
      const scrollTop = container.scrollTop
      
      // Only adjust padding when scroll is near bottom
      const isNearBottom = scrollHeight - scrollTop - containerHeight < 80
      
      if (isNearBottom) {
        // Check only code blocks in the last message (to prevent excessive padding)
        const lastMessage = container.querySelector('.max-w-3xl > div:last-child')
        let additionalPadding = 0
        
        if (lastMessage) {
          const codeBlocks = lastMessage.querySelectorAll('.code-block')
          if (codeBlocks.length > 0) {
            // Consider only the height of code blocks in the last message
            const lastCodeBlock = codeBlocks[codeBlocks.length - 1]
            const rect = lastCodeBlock.getBoundingClientRect()
            
            // Add additional padding only when code block height is over 150px
            if (rect.height > 150) {
              additionalPadding = Math.min(rect.height * 0.3, 100) // Max 100px additional padding
            }
          }
        }
        
        // Base padding + limited additional padding
        const basePadding = isMobile ? 320 : 160
        const newPadding = Math.max(basePadding, basePadding + additionalPadding)
        
        // Increase threshold to prevent unnecessary padding changes
        const threshold = 30
        
        if (Math.abs(newPadding - dynamicPadding) > threshold) {
          setDynamicPadding(newPadding)
        }
      } else {
        // Restore base padding when scroll is at top
        const basePadding = isMobile ? 320 : 160
        if (dynamicPadding > basePadding) {
          setDynamicPadding(basePadding)
        }
      }
    }
  }, [dynamicPadding, isMobile])

  // Generate unique ID
  const generateUniqueId = (prefix: string) => {
    return `${prefix}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
  }

  // Adjust padding and scroll when streaming stops
  const handleAbort = () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
      abortControllerRef.current = null
    }
    streamingInProgress.current = false
    setIsStreaming(false)
    setRegeneratingMessageId(null)
    setStreamingMessageId(null)
    
    // ìƒíƒœ ë¦¬ì…‹ì„ ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ í™•ì‹¤ížˆ ì ìš©ë˜ë„ë¡ í•¨
    setTimeout(() => {
      console.log('=== handleAbort - First safety check ===')
      setRegeneratingMessageId(null)
      setIsStreaming(false)
    }, 100)
    
    setTimeout(() => {
      console.log('=== handleAbort - Final safety check ===')
      setRegeneratingMessageId(null)
      setIsStreaming(false)
    }, 500)
    
    // Adjust padding and scroll
    adjustDynamicPadding()
    scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom
  }

  // Handle image upload from ChatInput
  const handleImageUpload = useCallback((images: File[]) => {
    setUploadedImages(images)
  }, [])

  // Continue with new request after short delay
  // ë³‘ë ¬ ë”¥ë¦¬ì„œì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
  const handleParallelDeepResearch = async (
    subQuestions: string[],
    originalQuery: string,
    modelId: string,
    assistantMessageId: string
  ) => {
    try {
      console.log('ðŸš€ Starting parallel sub-question analysis');
      console.log('Sub-questions:', subQuestions);
      console.log('Original query:', originalQuery);
      console.log('Model ID:', modelId);
      console.log('Assistant message ID:', assistantMessageId);
      
      // ê° sub-questionì— ê³ ìœ  ID ìƒì„±
      const subQuestionData = subQuestions.map((question, index) => ({
        id: `subq_${Date.now()}_${index}`,
        question,
        index
      }));
      
      console.log('Sub-question data with IDs:', subQuestionData);
      
      // ëª¨ë“  sub-questionì„ ë³‘ë ¬ë¡œ ë¶„ì„
      const analysisPromises = subQuestionData.map(async (subQuestionItem) => {
        const { id, question, index } = subQuestionItem;
        console.log(`ðŸ“Š Starting analysis ${index + 1} (${id}): ${question}`);
        
        try {
          const response = await fetch(`/api/deepresearch/subquestion-analysis`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              subQuestion: question,
              originalQuery,
              modelId,
              context: '',
              previousSteps: []
            })
          });

          if (!response.ok) {
            throw new Error(`Analysis failed for: ${question}`);
          }

          const result = await response.json();
          console.log(`âœ… Completed analysis ${index + 1} (${id}): ${question}`);
          console.log('ðŸ” Sub-question analysis result:', result);
          console.log('ðŸ” Sub-question analysis keys:', Object.keys(result));
          console.log('ðŸ” Sub-question analysis content:', result.analysis);
          
          // ê° ë¶„ì„ ì™„ë£Œ ì‹œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ - ê³ ìœ  IDë¡œ ë§¤í•‘
          setMessages(prev => 
            prev.map(m => 
              m.id === assistantMessageId 
                ? { 
                    ...m,
                    deepResearchStepInfo: {
                      ...m.deepResearchStepInfo,
                      [id]: {
                        title: `Analysis: ${question}`,
                        content: result.analysis?.analysis || result.analysis || 'ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.',
                        isComplete: true,
                        index: index,
                        subQuestionId: id,
                        originalQuestion: question
                      }
                    }
                  }
                : m
            )
          );
          
          return {
            analysis: result.analysis?.analysis || result.analysis || 'ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.',
            content: result.analysis?.analysis || result.analysis || 'ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.',
            subQuestionId: id,
            originalQuestion: question,
            index: index
          };
        } catch (error) {
          console.error(`âŒ Failed analysis ${index + 1} (${id}):`, error);
          
          // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ìƒíƒœ ì—…ë°ì´íŠ¸
          setMessages(prev => 
            prev.map(m => 
              m.id === assistantMessageId 
                ? { 
                    ...m,
                    deepResearchStepInfo: {
                      ...m.deepResearchStepInfo,
                      [id]: {
                        title: `Analysis: ${question}`,
                        content: `âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'Unknown error'}`,
                        isComplete: false,
                        hasError: true,
                        index: index,
                        subQuestionId: id,
                        originalQuestion: question
                      }
                    }
                  }
                : m
            )
          );
          
          return null;
        }
      });

      // ëª¨ë“  ë¶„ì„ ì™„ë£Œ ëŒ€ê¸°
      console.log('â³ Waiting for all analyses to complete...');
      const analysisResults = await Promise.all(analysisPromises);
      const validResults = analysisResults.filter(result => result !== null);
      
      console.log(`âœ… All analyses completed: ${validResults.length}/${subQuestions.length} successful`);
      console.log('Valid results:', validResults);
      console.log('Valid results details:', validResults.map(r => ({
        subQuestionId: r.subQuestionId,
        originalQuestion: r.originalQuestion,
        index: r.index,
        hasAnalysis: !!r.analysis,
        hasContent: !!r.content,
        analysisLength: r.analysis?.length || 0
      })));

      if (validResults.length === 0) {
        throw new Error('ëª¨ë“  sub-question ë¶„ì„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }

      // ì¢…í•© ë¶„ì„ ìˆ˜í–‰
      console.log('ðŸ”„ Starting synthesis...');
      console.log('ðŸ”„ Valid results for synthesis:', validResults.length);
      console.log('ðŸ”„ Synthesis request data:', {
        query: originalQuery,
        modelId,
        analysisStepsCount: validResults.length
      });
      
      const synthesisResponse = await fetch(`/api/deepresearch/synthesis`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: originalQuery,
          modelId,
          analysisSteps: validResults.map(result => ({
            analysis: result.analysis || result.content || result,
            subQuestion: result.originalQuestion,
            index: result.index
          }))
        })
      });

      if (!synthesisResponse.ok) {
        const errorText = await synthesisResponse.text();
        console.error('Synthesis failed:', errorText);
        throw new Error(`Synthesis failed: ${errorText}`);
      }

      const synthesisResult = await synthesisResponse.json();
      console.log('âœ… Synthesis completed:', synthesisResult);
      console.log('ðŸ” Synthesis result keys:', Object.keys(synthesisResult));
      console.log('ðŸ” Synthesis content:', synthesisResult.synthesis);

      // ì¢…í•© ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
      const synthesisId = `synthesis_${Date.now()}`;
      setMessages(prev => 
        prev.map(m => 
          m.id === assistantMessageId 
            ? { 
                ...m,
                deepResearchStepInfo: {
                  ...m.deepResearchStepInfo,
                  [synthesisId]: {
                    title: 'Synthesis Analysis',
                    content: synthesisResult.synthesis || 'ì¢…í•© ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.',
                    isComplete: true,
                    isSynthesis: true
                  }
                }
              }
            : m
        )
      );

      // ìµœì¢… ë‹µë³€ ìƒì„±
      console.log('ðŸŽ¯ Generating final answer...');
      console.log('ðŸŽ¯ Final answer request data:', {
        query: originalQuery,
        modelId,
        analysisStepsCount: validResults.length,
        synthesisLength: synthesisResult.synthesis?.length || 0
      });
      
      const finalAnswerResponse = await fetch(`/api/deepresearch/final-answer`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: originalQuery,
          modelId,
          analysisSteps: validResults.map(result => ({
            analysis: result.analysis || result.content || result,
            subQuestion: result.originalQuestion,
            index: result.index
          })),
          synthesis: synthesisResult.synthesis
        })
      });

      if (!finalAnswerResponse.ok) {
        const errorText = await finalAnswerResponse.text();
        console.error('Final answer generation failed:', errorText);
        throw new Error(`Final answer generation failed: ${errorText}`);
      }

      const finalAnswerResult = await finalAnswerResponse.json();
      console.log('ðŸŽ‰ Final answer generated:', finalAnswerResult);
      console.log('ðŸ” Final answer result keys:', Object.keys(finalAnswerResult));
      console.log('ðŸ” Final answer content:', finalAnswerResult.finalAnswer);
      console.log('ðŸ” Final answer length:', finalAnswerResult.finalAnswer?.length);

      // ìµœì¢… ë‹µë³€ìœ¼ë¡œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
      const finalAnswerId = `final_answer_${Date.now()}`;
      const finalAnswerContent = finalAnswerResult.finalAnswer || finalAnswerResult.answer || 'ìµœì¢… ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.';
      
      console.log('ðŸ” Final answer processing:');
      console.log('- assistantMessageId:', assistantMessageId);
      console.log('- finalAnswerId:', finalAnswerId);
      console.log('- finalAnswerContent length:', finalAnswerContent.length);
      console.log('- finalAnswerContent preview:', finalAnswerContent.substring(0, 100));
      
      setMessages(prev => {
        console.log('ðŸ” Current messages before final answer update:', prev.length);
        const targetMessage = prev.find(m => m.id === assistantMessageId);
        console.log('ðŸ” Target message found:', !!targetMessage);
        console.log('ðŸ” Target message content length:', targetMessage?.content.length);
        
        const updatedMessages = prev.map(m => 
          m.id === assistantMessageId 
            ? { 
                ...m,
                content: m.content + '\n\n## ìµœì¢… ë‹µë³€\n\n' + finalAnswerContent,
                isDeepResearchComplete: true,
                deepResearchStepType: 'final' as const, // ìµœì¢… ë‹µë³€ ë‹¨ê³„ë¡œ ì„¤ì •
                deepResearchStepInfo: {
                  ...m.deepResearchStepInfo,
                  [finalAnswerId]: {
                    title: 'Final Answer',
                    content: finalAnswerContent,
                    isComplete: true,
                    isFinalAnswer: true
                  }
                }
              }
            : m
        );
        
        console.log('ðŸ” Updated messages after final answer:', updatedMessages.length);
        const updatedTargetMessage = updatedMessages.find(m => m.id === assistantMessageId);
        console.log('ðŸ” Updated target message content length:', updatedTargetMessage?.content.length);
        
        return updatedMessages;
      });

      // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¦‰ì‹œ ì¢…ë£Œ
      console.log('ðŸ”„ Ending streaming state immediately...');
      setIsStreaming(false);
      setStreamingMessageId(null);
      setIsSubmitting(false); // ì œì¶œ ìƒíƒœë„ í•´ì œ
      streamingInProgress.current = false;
      
      // ì¶”ê°€ ì•ˆì „ìž¥ì¹˜ - ì—¬ëŸ¬ ë²ˆ ì‹œë„
      setTimeout(() => {
        console.log('ðŸ”„ Second attempt to end streaming state...');
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        streamingInProgress.current = false;
      }, 100);
      
      setTimeout(() => {
        console.log('ðŸ”„ Final attempt to end streaming state...');
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        streamingInProgress.current = false;
      }, 1000);

      console.log('ðŸŽ‰ Parallel deep research completed successfully!');
      
    } catch (error) {
      console.error('âŒ Parallel deep research error:', error);
      console.error('âŒ Error stack:', error instanceof Error ? error.stack : 'No stack trace');
      console.error('âŒ Error details:', {
        message: error instanceof Error ? error.message : String(error),
        assistantMessageId,
        originalQuery,
        modelId
      });
      
      // ì—ëŸ¬ ì²˜ë¦¬
      const errorContent = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      setMessages(prev => 
        prev.map(m => 
          m.id === assistantMessageId 
            ? { 
                ...m,
                content: m.content + '\n\nâš ï¸ ë³‘ë ¬ ë”¥ë¦¬ì„œì¹˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + errorContent,
                hasDeepResearchError: true
              }
            : m
        )
      );
      
      // ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¦‰ì‹œ ì¢…ë£Œ (ì—ëŸ¬ ì‹œ)
      console.log('ðŸ”„ Ending streaming state due to error...');
      setIsStreaming(false);
      setStreamingMessageId(null);
      setIsSubmitting(false); // ì œì¶œ ìƒíƒœë„ í•´ì œ
      streamingInProgress.current = false;
      
      // ì¶”ê°€ ì•ˆì „ìž¥ì¹˜
      setTimeout(() => {
        console.log('ðŸ”„ Second attempt to end streaming state (error)...');
        setIsStreaming(false);
        setStreamingMessageId(null);
        setIsSubmitting(false);
        streamingInProgress.current = false;
      }, 100);
    }
  };

  const sendMessageToAI = async (message: string, agentInfo: {id: string, type: string}, isRegeneration: boolean = false, images?: File[]) => {
    console.log('=== sendMessageToAI function called ===')
    console.log('message:', message)
    console.log('agentInfo:', agentInfo)
    console.log('isRegeneration:', isRegeneration)
    console.log('images:', images)
    console.log('session?.user?.email:', session?.user?.email)
    
    if (!session?.user?.email) {
      console.error('User authentication required')
      return
    }

    // Abort if already streaming and start new request
    if (streamingInProgress.current) {
      handleAbort()
      // Wait briefly after message update
      await new Promise(resolve => setTimeout(resolve, 100))
    }

    // Enhanced duplicate prevention using message content + timestamp + deep research state
    const currentTime = Date.now()
    const messageKey = `${message}_${images?.length || 0}_${isRegeneration}_${isDeepResearchActive}`
    const lastMessageData = sessionStorage.getItem(`lastMessage_${chatId}`)
    
    if (lastMessageData) {
      try {
        const { message: lastMsg, timestamp: lastTime } = JSON.parse(lastMessageData)
        // Block if same message within 3 seconds (increased for deep research)
        if (lastMsg === messageKey && currentTime - lastTime < 3000) {
          console.log('Duplicate AI request blocked:', messageKey)
          return
        }
      } catch (e) {
        // If parsing fails, continue with old logic
        if (lastMessageData === messageKey) {
          console.log('Duplicate AI request blocked (fallback):', messageKey)
          return
        }
      }
    }
    
    sessionStorage.setItem(`lastMessage_${chatId}`, JSON.stringify({
      message: messageKey,
      timestamp: currentTime
    }))

    // Abort previous request if exists
    if (abortControllerRef.current) {
      abortControllerRef.current.abort()
    }

    // Create new AbortController
    const abortController = new AbortController()
    abortControllerRef.current = abortController
    streamingInProgress.current = true
    setIsStreaming(true)
    
    // Adjust padding and scroll
    adjustDynamicPadding()
    scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom

    try {
      let response: Response

      if (images && images.length > 0) {
        // Use FormData when images are present
        const formData = new FormData()
        formData.append('message', message)
        if (agentInfo.type === 'agent') {
          formData.append('agentId', agentInfo.id)
        } else {
          formData.append('modelId', agentInfo.id)
        }
        formData.append('modelType', agentInfo.type)
        formData.append('isRegeneration', isRegeneration.toString())
        formData.append('isDeepResearchActive', isDeepResearchActive.toString())
        formData.append('isGlobeActive', isGlobeActive.toString())
        
        // Add image files
        images.forEach((image) => {
          formData.append('images', image)
        })
        
        // Add userId for authentication
        formData.append('userId', session?.user?.email || '')
        
        response = await fetch(`/api/chat/${chatId}`, {
          method: 'POST',
          body: formData
        })
      } else {
        // Use JSON for text-only messages
        response = await fetch(`/api/chat/${chatId}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            message,
            agentId: agentInfo.type === 'agent' ? agentInfo.id : undefined,
            modelId: agentInfo.type === 'model' ? agentInfo.id : undefined,
            modelType: agentInfo.type,
            isRegeneration,
            isDeepResearchActive,
            isGlobeActive,
            userId: session?.user?.email
          })
        })
      }

      if (!response.ok) {
        const errorText = await response.text()
        console.error('API response error:', errorText)
        
        // Parse error message from response
        let errorMessage = 'Message sending failed'
        try {
          const errorData = JSON.parse(errorText)
          if (errorData.error) {
            errorMessage = errorData.error
          }
        } catch (e) {
          // If parsing fails, use the raw error text
          errorMessage = errorText || `HTTP ${response.status} Error`
        }
        
        throw new Error(errorMessage)
      }

      // Process streaming response
      const reader = response.body?.getReader()
      const decoder = new TextDecoder()

      if (reader) {
        let assistantContent = ''
        let assistantMessageId = ''

        const processStream = async () => {
          try {
            while (true) {
              if (abortController.signal.aborted) {
                break
              }

              const { done, value } = await reader.read()
              if (done) {
                break
              }

              const chunk = decoder.decode(value)
              const lines = chunk.split('\n')

              for (const line of lines) {
                if (line.startsWith('data: ')) {
                  try {
                    const data = JSON.parse(line.slice(6))
                    
                    if (data.error) {
                      console.error('AI response error:', data.error)
                      break
                    }

                    if (data.messageId && !assistantMessageId) {
                      assistantMessageId = data.messageId
                      setStreamingMessageId(assistantMessageId)
                      // Add new message ID
                      setNewMessageIds(prev => new Set([...prev, assistantMessageId]))
                      // Initialize AI response message
                      setMessages(prev => [...prev, {
                        id: assistantMessageId,
                        role: "assistant" as const,
                        content: '',
                        timestamp: new Date(),
                      }])
                      // Scroll immediately when new AI response message is generated
                      adjustDynamicPadding()
                      scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom
                    }

                    if (data.content) {
                      assistantContent += data.content
                      // Real-time update of AI response
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { ...m, content: assistantContent }
                            : m
                        )
                      )
                      // Maintain scroll position and adjust padding during streaming (frequency adjusted)
                      if (assistantContent.length % 100 === 0) {
                        adjustDynamicPadding()
                        scrollToBottomSmooth(true) // Set force=true to ensure scroll to bottom
                      }
                    }

                    // Handle Deep Research streaming
                    if (data.deepResearchStream) {
                      // ê³„íšëœ ìŠ¤íƒ­ë“¤ ì²˜ë¦¬
                      if (data.stepInfo && data.stepInfo.plannedSteps) {
                        setDeepResearchPlannedSteps(data.stepInfo.plannedSteps)
                      }
                      
                      // ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ í™•ì¸
                      if (data.stepInfo?.useParallelProcessing && data.stepInfo?.subQuestions) {
                        console.log('ðŸš€ Starting parallel deep research processing');
                        console.log('ðŸš€ Step info:', data.stepInfo);
                        console.log('ðŸš€ Sub-questions from step info:', data.stepInfo.subQuestions);
                        console.log('ðŸš€ Assistant message ID:', assistantMessageId);
                        
                        // Sub-questionsë¥¼ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ìž¥
                        assistantContent += data.content;
                        
                        // ë³‘ë ¬ ì²˜ë¦¬ ì‹œìž‘
                        handleParallelDeepResearch(
                          data.stepInfo.subQuestions,
                          data.stepInfo.originalQuery,
                          data.stepInfo.modelId,
                          assistantMessageId
                        );
                      } else {
                        // ê¸°ì¡´ ìˆœì°¨ ì²˜ë¦¬ ë¡œì§
                        // ìŠ¤íƒ­ë³„ ì²˜ë¦¬: Sub-questionsì™€ ìµœì¢…ë‹µë³€(final)ì„ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ìž¥
                        if (data.stepType === 'final' || 
                            (data.stepType === 'step' && data.stepInfo?.title === 'Sub-questions Generated')) {
                          // Sub-questionsì™€ ìµœì¢…ë‹µë³€ì€ ë©”ì‹œì§€ ë‚´ìš©ìœ¼ë¡œ ì €ìž¥í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ
                          assistantContent += data.content
                        }
                        // ë‹¤ë¥¸ ë¶„ì„ ê³¼ì •(step, synthesis)ì€ ë©”ì‹œì§€ ë‚´ìš©ì— ì €ìž¥í•˜ì§€ ì•ŠìŒ (ë”¥ë¦¬ì„œì¹˜ ì»´í¬ë„ŒíŠ¸ì—ì„œë§Œ í‘œì‹œ)
                      }
                      
                      // Real-time update of AI response with deep research streaming
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { 
                                ...m, 
                                content: assistantContent, 
                                isDeepResearch: true, 
                                deepResearchStepType: data.stepType,
                                deepResearchStepInfo: {
                                  ...data.stepInfo || {},
                                  plannedSteps: deepResearchPlannedSteps.length > 0 ? deepResearchPlannedSteps : data.stepInfo?.plannedSteps,
                                  currentStepContent: data.content,
                                  currentStepType: data.stepType
                                }
                              }
                            : m
                        )
                      )
                      // More frequent scrolling for deep research steps
                      adjustDynamicPadding()
                      scrollToBottomSmooth(true)
                    }

                    // Handle Deep Research final result
                    if (data.deepResearchFinal) {
                      assistantContent = data.content // ìµœì¢… ê²°ê³¼ë¡œ ì™„ì „ížˆ ëŒ€ì²´
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { ...m, content: assistantContent, isDeepResearch: true, isDeepResearchComplete: true }
                            : m
                        )
                      )
                      adjustDynamicPadding()
                      scrollToBottomSmooth(true)
                    }

                    // Handle Deep Research error
                    if (data.deepResearchError) {
                      assistantContent += data.content
                      setMessages(prev => 
                        prev.map(m => 
                          m.id === assistantMessageId 
                            ? { ...m, content: assistantContent, isDeepResearch: true, hasDeepResearchError: true }
                            : m
                        )
                      )
                      adjustDynamicPadding()
                      scrollToBottomSmooth(true)
                    }

                    if (data.titleGenerated) {
                      // Title has been generated, immediately refresh sidebar
                      const eventDetail = { chatId: data.chatId, title: data.title }
                      window.dispatchEvent(new CustomEvent('chatTitleUpdated', { 
                        detail: eventDetail
                      }))
                    }

                    if (data.done) {
                      console.log('=== Streaming completed (data.done=true) ===')
                      
                      // ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œì ì—ì„œ ì¦‰ì‹œ ìƒíƒœ ë¦¬ì…‹
                      console.log('=== Immediate state reset on streaming completion ===')
                      setIsStreaming(false)
                      setRegeneratingMessageId(null)
                      setStreamingMessageId(null)
                      streamingInProgress.current = false
                      
                      break
                    }
                  } catch (e) {
                    // Ignore JSON parsing errors
                  }
                }
              }
            }
          } catch (error) {
            if (error instanceof Error && error.name === 'AbortError') {
              // Stream processing aborted
            } else {
              console.error('Stream processing error:', error)
            }
          }
        }

        await processStream()
      }
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        // AI message sending aborted
      } else {
        console.error('AI message sending error:', error)
        // Show error toast to user
        const errorMessage = error instanceof Error ? error.message : 'An unexpected error occurred'
        toast.error(errorMessage)
        
        // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ìž¬ìƒì„± ìƒíƒœ ë¦¬ì…‹
        console.log('Resetting regenerating state due to error')
        setRegeneratingMessageId(null)
      }
    } finally {
      console.log('=== sendMessageToAI finally block ===')
      console.log('Resetting all streaming states')
      
      // ì¦‰ì‹œ ìƒíƒœ ë¦¬ì…‹
      streamingInProgress.current = false
      setIsStreaming(false)
      setRegeneratingMessageId(null)
      setStreamingMessageId(null)
      abortControllerRef.current = null
      console.log('All streaming states reset')
      
      // ìƒíƒœ ë¦¬ì…‹ì„ ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ í™•ì‹¤ížˆ ì ìš©ë˜ë„ë¡ í•¨
      setTimeout(() => {
        console.log('=== First safety check - Reset regeneration state ===')
        setRegeneratingMessageId(null)
        setIsStreaming(false)
      }, 100)
      
      setTimeout(() => {
        console.log('=== Second safety check - Reset regeneration state ===')
        setRegeneratingMessageId(null)
        setIsStreaming(false)
      }, 500)
      
      setTimeout(() => {
        console.log('=== Final safety check - Force reset regeneration state ===')
        setRegeneratingMessageId(null)
        setIsStreaming(false)
      }, 1000) // 1ì´ˆ í›„ ê°•ì œ ë¦¬ì…‹
      
      // Final padding adjustment and forced scroll when streaming completes
      adjustDynamicPadding()
      scrollToBottomSmooth(true) // Force scroll
      
      // Scroll one more time after streaming completes (after DOM updates)
      setTimeout(() => {
        scrollToBottomSmooth()
      }, 100)
      
      // Additional scroll handling - wait for DOM to fully render after streaming
      setTimeout(() => {
        scrollToBottomSmooth()
      }, 100)
      
      // Final scroll adjustment
      setTimeout(() => {
        scrollToBottomSmooth()
      }, 500)
      
      // Restore base padding after streaming completes
      setTimeout(() => {
        setDynamicPadding(isMobile ? 320 : 160)
      }, 2000)
      
      // Clear duplicate prevention after request completes
      setTimeout(() => {
        sessionStorage.removeItem(`lastMessage_${chatId}`)
      }, 3000) // Clear after 3 seconds
    }
  }

  // Load chat history when chatId or session changes
  useEffect(() => {
    let isCancelled = false
    
    console.log('=== ChatPage useEffect triggered ===')
    console.log('chatId:', chatId)
    console.log('session?.user?.email:', session?.user?.email)
    console.log('sessionStatus:', sessionStatus)
    
    // Initialize loading state
    setHistoryLoaded(false)
    setShowSkeleton(true)
    
    // Ensure minimum skeleton UI display time (300ms)
    const minSkeletonDisplayTime = 300
    const skeletonStartTime = Date.now()
    
    if (chatId && session?.user?.email) {
      // Get chat history from API
      const loadChatHistory = async () => {
        if (isCancelled) return

        try {
          console.log('=== Fetching chat history ===')
          console.log('URL:', `/api/chat/${chatId}`)
          const response = await fetch(`/api/chat/${chatId}`)
          console.log('Response status:', response.status)
          if (isCancelled) return
          
          if (response.status === 401 || response.status === 404) {
            // ì¸ì¦ ì˜¤ë¥˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì—†ìŒ ì‹œ í™ˆíŽ˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
            console.log('Chat session not found or access denied, redirecting to home')
            toast.error('ì±„íŒ… ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™ˆìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.')
            router.push('/')
            return
          }
          
          if (response.ok) {
            const data = await response.json()
            console.log('Chat history data:', data)
            if (isCancelled) return
            
            // Convert timestamp to Date object and process rating info
            const messagesWithDateTimestamp = (data.messages || []).map((msg: any) => {
              // Handle timestamp conversion properly for SQLite (integer) and PostgreSQL (string)
              let timestamp: Date;
              if (msg.timestamp) {
                // If timestamp is a number (SQLite), it's already in milliseconds
                // If timestamp is a string (PostgreSQL), Date constructor can handle it
                timestamp = new Date(msg.timestamp);
                // Check if the date is valid
                if (isNaN(timestamp.getTime())) {
                  // If invalid, use current time as fallback
                  timestamp = new Date();
                }
              } else {
                // If no timestamp, use current time
                timestamp = new Date();
              }
              
              return {
                ...msg,
                timestamp
              };
            })
            console.log('Processed messages:', messagesWithDateTimestamp)
            
            // Load rating information from messages
            const likedMessageIds = new Set<string>()
            const dislikedMessageIds = new Set<string>()
            
            messagesWithDateTimestamp.forEach((msg: any) => {
              if (msg.rating === 1) {
                likedMessageIds.add(msg.id)
              } else if (msg.rating === -1) {
                dislikedMessageIds.add(msg.id)
              }
            })
            
            // Update rating states
            setLikedMessages(likedMessageIds)
            setDislikedMessages(dislikedMessageIds)
            
            // Process messages in a non-blocking way
            const processMessages = () => {
              return new Promise<void>((resolve) => {
                if (isCancelled) {
                  resolve()
                  return
                }
                
                // Process messages consistently regardless of count
                // Set messages directly instead of initializing with empty array
                setMessages(messagesWithDateTimestamp)
                console.log('Messages set, length:', messagesWithDateTimestamp.length)
                
                // Auto-generate AI response if last message is user message AND there's agent info in localStorage
                // This only happens for newly created chats where user message was just sent
                const agentInfo = localStorage.getItem(`chat_${chatId}_agent`)
                if (messagesWithDateTimestamp.length > 0 && !streamingInProgress.current && agentInfo) {
                  const lastMessage = messagesWithDateTimestamp[messagesWithDateTimestamp.length - 1]
                  
                  // Only generate response if:
                  // 1. Last message is from user
                  // 2. There's exactly 1 message (first conversation)
                  // 3. Agent info exists in localStorage
                  if (lastMessage.role === 'user' && messagesWithDateTimestamp.length === 1) {
                    if (!isCancelled) {
                      const parsedAgentInfo = JSON.parse(agentInfo)
                      
                      // Call streaming API with isRegeneration=true to prevent duplicate user message saving
                      sendMessageToAI(lastMessage.content, parsedAgentInfo, true)
                      
                      // Clean up localStorage after use (delay to prevent race condition)
                      setTimeout(() => {
                        localStorage.removeItem(`chat_${chatId}_agent`)
                      }, 1000)
                    }
                  } else {
                    // Clean up localStorage if it exists but we're not using it
                    localStorage.removeItem(`chat_${chatId}_agent`)
                  }
                }
                
                // Always resolve the promise
                resolve()
              })
            }
            
            // Process messages asynchronously
            await processMessages()
          } else {
            console.error('Failed to load chat history')
            console.error('Response status:', response.status)
            const errorText = await response.text()
            console.error('Error response:', errorText)
          }
        } catch (error) {
          if (!isCancelled) {
            console.error('Chat history load error:', error)
          }
        } finally {
          if (!isCancelled) {
            // Ensure minimum skeleton UI display time (300ms)
            const elapsedTime = Date.now() - skeletonStartTime
            const remainingTime = Math.max(0, minSkeletonDisplayTime - elapsedTime)
            
            setTimeout(() => {
              if (!isCancelled) {
                // Prevent render blocking when there are many messages
                requestAnimationFrame(() => {
                  setHistoryLoaded(true) // Mark history load as completed
                  setShowSkeleton(false) // Hide skeleton UI
                  console.log('=== History loading completed ===')
                  console.log('historyLoaded: true, showSkeleton: false')
                  
                  // Move to bottom immediately after content is loaded (without animation)
                  // ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ìŠ¤í¬ë¡¤ ì²˜ë¦¬í•˜ì—¬ í™•ì‹¤í•˜ê²Œ ë§¨ ë°‘ìœ¼ë¡œ ì´ë™
                  setTimeout(() => {
                    scrollToBottomInstant()
                  }, 100)
                  
                  // ì¶”ê°€ ìŠ¤í¬ë¡¤ ì²˜ë¦¬ - DOM ì™„ì „ ë Œë”ë§ í›„
                  setTimeout(() => {
                    scrollToBottomInstant()
                  }, 300)
                  
                  // ìµœì¢… ìŠ¤í¬ë¡¤ ì²˜ë¦¬
                  setTimeout(() => {
                    scrollToBottomInstant()
                  }, 600)
                })
              }
            }, remainingTime)
          }
        }
      }

      loadChatHistory()
    } else {
      // chatIdë‚˜ sessionì´ ì—†ìœ¼ë©´ ìµœì†Œ ì‹œê°„ í›„ ë¡œë”© ì™„ë£Œ ì²˜ë¦¬
      const elapsedTime = Date.now() - skeletonStartTime
      const remainingTime = Math.max(0, minSkeletonDisplayTime - elapsedTime)
      
      setTimeout(() => {
        if (!isCancelled) {
          requestAnimationFrame(() => {
            setHistoryLoaded(true)
            setShowSkeleton(false)
          })
        }
      }, remainingTime)
    }

    // Cleanup function
    return () => {
      isCancelled = true
    }
  }, [chatId, session?.user?.email, isMobile])

  // Handle session status changes
  useEffect(() => {
    // Reset history load state when session changes
    if (!session?.user?.email) {
      setHistoryLoaded(false)
      setShowSkeleton(false)
      setMessages([])
    }
  }, [session?.user?.email])

  // Handle scroll on message change (also works when chat ID changes)
  const [isInitialLoad, setIsInitialLoad] = useState(true)
  
  useEffect(() => {
    if (messages.length > 0) {
      if (isInitialLoad) {
        // Move to bottom immediately on first load (without animation)
        setTimeout(() => scrollToBottomInstant(), 100)
        setTimeout(() => scrollToBottomInstant(), 300)
        setTimeout(() => scrollToBottomInstant(), 600)
        setIsInitialLoad(false)
      } else {
        // Smooth scroll when new message is added
        setTimeout(() => scrollToBottomSmooth(true), 100)
        setTimeout(() => scrollToBottomInstant(), 300)
        setTimeout(() => scrollToBottomInstant(), 600)
      }
      
      // Adjust padding when messages change
      setTimeout(() => adjustDynamicPadding(), 200)
      
      // Clean up new message IDs after animation completes
      setTimeout(() => {
        setNewMessageIds(new Set())
      }, 1000)
    }
  }, [messages, isInitialLoad, adjustDynamicPadding])
  
  // Reset to initial load state when chatId changes
  useEffect(() => {
    setIsInitialLoad(true)
    const basePadding = isMobile !== undefined ? (isMobile ? 320 : 160) : 240
    setDynamicPadding(basePadding) // Reset padding too
  }, [chatId, isMobile])

  // Check if selected model supports multimodal input
  const supportsMultimodal = useMemo(() => {
    if (!selectedModel) return false
    
    if (selectedModel.type === 'agent') {
      // For agents, check both agent's supportsMultimodal and underlying model's supportsMultimodal
      const agentSupports = selectedModel.supportsMultimodal === true || selectedModel.supportsMultimodal === 1
      const modelSupports = selectedModel.modelSupportsMultimodal === true || selectedModel.modelSupportsMultimodal === 1
      return agentSupports || modelSupports
    } else if (selectedModel.type === 'model') {
      // For public models, check supportsMultimodal field
      return selectedModel.supportsMultimodal === true || selectedModel.supportsMultimodal === 1
    }
    
    return false
  }, [selectedModel])

  // Add scroll event listener - prevent auto scroll when user scrolls
  useEffect(() => {
    const container = messagesContainerRef.current
    if (!container) return

    let scrollTimeout: NodeJS.Timeout | null = null

    const handleScroll = () => {
      // ìŠ¤í¬ë¡¤ ì´ë²¤íŠ¸ ë””ë°”ìš´ì‹±ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
      if (scrollTimeout) {
        clearTimeout(scrollTimeout)
      }
      
      scrollTimeout = setTimeout(() => {
        // Disable auto scroll flag when user scrolls manually
        if (!isScrollingToBottom.current) {
          const { scrollTop, scrollHeight, clientHeight } = container
          const isAtBottom = scrollHeight - scrollTop - clientHeight < 80
          
          // ê¸´ ë©”ì‹œì§€ì—ì„œ ìŠ¤í¬ë¡¤ ì¤‘ ë Œë”ë§ ì•ˆì •ì„± í™•ë³´
          if (!isAtBottom) {
            // ìŠ¤í¬ë¡¤ì´ ìƒë‹¨ìœ¼ë¡œ ì´ë™í•  ë•Œ ë Œë”ë§ ê°•ì œ ì—…ë°ì´íŠ¸ ë°©ì§€
            container.style.contentVisibility = 'auto'
          }
        }
      }, 16) // 60fpsì— ë§žì¶° ë””ë°”ìš´ì‹±
    }

    container.addEventListener('scroll', handleScroll, { passive: true })
    
    return () => {
      container.removeEventListener('scroll', handleScroll)
      if (scrollTimeout) {
        clearTimeout(scrollTimeout)
      }
    }
  }, [])

  // ResizeObserverë¥¼ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  í¬ê¸° ë³€ê²½ ê°ì§€ ë° ìžë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    const container = messagesContainerRef.current
    if (!container) return

    const resizeObserver = new ResizeObserver((entries) => {
      for (const entry of entries) {
        // ì½˜í…ì¸  í¬ê¸°ê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œ ì‚¬ìš©ìžê°€ í•˜ë‹¨ ê·¼ì²˜ì— ìžˆìœ¼ë©´ ìžë™ ìŠ¤í¬ë¡¤
        const { scrollTop, scrollHeight, clientHeight } = container
        const isNearBottom = scrollHeight - scrollTop - clientHeight < 200
        
        if (isNearBottom && !isScrollingToBottom.current) {
          // ì§§ì€ ì§€ì—° í›„ ìŠ¤í¬ë¡¤ (DOM ì—…ë°ì´íŠ¸ ëŒ€ê¸°)
          setTimeout(() => {
            scrollToBottomInstant()
          }, 50)
        }
      }
    })

    // ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ê´€ì°°
    resizeObserver.observe(container)
    
    // ë‚´ë¶€ ì½˜í…ì¸  ì»¨í…Œì´ë„ˆë„ ê´€ì°°
    const innerContainer = container.querySelector('.max-w-full')
    if (innerContainer) {
      resizeObserver.observe(innerContainer)
    }

    return () => {
      resizeObserver.disconnect()
    }
  }, [])

  // Clean up streaming on component unmount
  useEffect(() => {
    return () => {
      if (abortControllerRef.current) {
        abortControllerRef.current.abort()
      }
      streamingInProgress.current = false
      setIsStreaming(false)
    }
  }, [])

  // Move to bottom immediately without animation
  const scrollToBottomInstant = () => {
    if (messagesContainerRef.current) {
      const container = messagesContainerRef.current
      isScrollingToBottom.current = true
      
      // ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ í™•ì‹¤í•˜ê²Œ ë§¨ ë°‘ìœ¼ë¡œ ìŠ¤í¬ë¡¤
      const scrollToMax = () => {
        // ìŠ¤í¬ë¡¤ ë†’ì´ë¥¼ ë‹¤ì‹œ ê³„ì‚°í•˜ì—¬ ìµœì‹  ê°’ ì‚¬ìš©
        const maxScrollTop = container.scrollHeight - container.clientHeight
        container.scrollTop = Math.max(0, maxScrollTop)
        lastScrollHeight.current = container.scrollHeight
      }
      
      // ì¦‰ì‹œ ìŠ¤í¬ë¡¤
      scrollToMax()
      
      // DOM ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë‹¤ì¤‘ ì‹œë„
      requestAnimationFrame(() => {
        scrollToMax()
        
        requestAnimationFrame(() => {
          scrollToMax()
          
          // 100ms í›„ í•œ ë²ˆ ë”
          setTimeout(() => {
            scrollToMax()
            
            // 300ms í›„ ìµœì¢… í™•ì¸
            setTimeout(() => {
              scrollToMax()
              isScrollingToBottom.current = false
            }, 300)
          }, 100)
        })
      })
    }
  }

  // Move to bottom smoothly with animation
  const scrollToBottomSmooth = (force: boolean = false) => {
    if (messagesContainerRef.current && !isScrollingToBottom.current) {
      const container = messagesContainerRef.current
      const newScrollHeight = container.scrollHeight
      
      // Don't scroll if scroll height hasn't changed (ignore if force is true)
      if (!force && newScrollHeight <= lastScrollHeight.current + 10) {
        return
      }
      
      isScrollingToBottom.current = true
      lastScrollHeight.current = newScrollHeight
      
      // ì‹¤ì œ ìµœëŒ€ ìŠ¤í¬ë¡¤ ìœ„ì¹˜ ê³„ì‚°
      const maxScrollTop = Math.max(0, newScrollHeight - container.clientHeight)
      
      // ë¶€ë“œëŸ½ê²Œ ìŠ¤í¬ë¡¤
      container.scrollTo({
        top: maxScrollTop,
        behavior: 'smooth'
      })
      
      // ìŠ¤í¬ë¡¤ ì™„ë£Œ í›„ ì—¬ëŸ¬ ë²ˆ í™•ì¸
      setTimeout(() => {
        const currentMaxScrollTop = Math.max(0, container.scrollHeight - container.clientHeight)
        if (container.scrollTop < currentMaxScrollTop - 20) {
          container.scrollTop = currentMaxScrollTop
        }
        
        // í•œ ë²ˆ ë” í™•ì¸
        setTimeout(() => {
          const finalMaxScrollTop = Math.max(0, container.scrollHeight - container.clientHeight)
          if (container.scrollTop < finalMaxScrollTop - 20) {
            container.scrollTop = finalMaxScrollTop
          }
          isScrollingToBottom.current = false
        }, 300)
      }, 600) // ì• ë‹ˆë©”ì´ì…˜ ì™„ë£Œ ëŒ€ê¸°
    }
  }

  const adjustHeight = () => {
    // Use fixed height
  }

  const handleInputChange = useCallback((e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setInputValue(e.target.value)
    
    // Automatically adjust textarea height
    const target = e.target as HTMLTextAreaElement
    target.style.height = 'auto'
    target.style.height = Math.min(target.scrollHeight, window.innerHeight * 0.3) + 'px'
  }, [])

  const handleKeyUp = useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === "Shift") {
      setIsShiftPressed(false)
    }
  }, [])

  const handleCompositionStart = useCallback(() => {
    setIsComposing(true)
  }, [])

  const handleCompositionEnd = useCallback(() => {
    setIsComposing(false)
  }, [])

  const handleCopyMessage = useCallback((content: string, messageId: string) => {
    navigator.clipboard.writeText(content)
    setCopiedMessageId(messageId)
    // 2ì´ˆ í›„ ë³µì‚¬ ìƒíƒœ ì´ˆê¸°í™”
    setTimeout(() => {
      setCopiedMessageId(null)
    }, 2000)
  }, [])

  const handleLikeMessage = useCallback(async (messageId: string) => {
    const isCurrentlyLiked = likedMessages.has(messageId)
    const newRating = isCurrentlyLiked ? 0 : 1
    
    // ë‚™ê´€ì  ì—…ë°ì´íŠ¸
    setLikedMessages((prev) => {
      const newSet = new Set(prev)
      if (isCurrentlyLiked) {
        newSet.delete(messageId)
      } else {
        newSet.add(messageId)
        // ì¢‹ì•„ìš” ì‹œ ì‹«ì–´ìš” ì œê±°
        setDislikedMessages((prevDisliked) => {
          const newDislikedSet = new Set(prevDisliked)
          newDislikedSet.delete(messageId)
          return newDislikedSet
        })
      }
      return newSet
    })

    // API í˜¸ì¶œ
    try {
      const response = await fetch(`/api/chat/${chatId}/rating`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messageId,
          rating: newRating
        })
      })

      if (response.status === 401 || response.status === 404) {
        // ì¸ì¦ ì˜¤ë¥˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì—†ìŒ ì‹œ í™ˆíŽ˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        router.push('/')
        return
      }

      if (!response.ok) {
        throw new Error('Failed to update rating')
      }
    } catch (error) {
      console.error('Error updating like:', error)
      // ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
      setLikedMessages((prev) => {
        const newSet = new Set(prev)
        if (isCurrentlyLiked) {
          newSet.add(messageId)
        } else {
          newSet.delete(messageId)
        }
        return newSet
      })
    }
  }, [chatId, likedMessages, router])

  const handleDislikeMessage = useCallback(async (messageId: string) => {
    const isCurrentlyDisliked = dislikedMessages.has(messageId)
    const newRating = isCurrentlyDisliked ? 0 : -1
    
    // ë‚™ê´€ì  ì—…ë°ì´íŠ¸
    setDislikedMessages((prev) => {
      const newSet = new Set(prev)
      if (isCurrentlyDisliked) {
        newSet.delete(messageId)
      } else {
        newSet.add(messageId)
        // ì‹«ì–´ìš” ì‹œ ì¢‹ì•„ìš” ì œê±°
        setLikedMessages((prevLiked) => {
          const newLikedSet = new Set(prevLiked)
          newLikedSet.delete(messageId)
          return newLikedSet
        })
      }
      return newSet
    })

    // API í˜¸ì¶œ
    try {
      const response = await fetch(`/api/chat/${chatId}/rating`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messageId,
          rating: newRating
        })
      })

      if (response.status === 401 || response.status === 404) {
        // ì¸ì¦ ì˜¤ë¥˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì—†ìŒ ì‹œ í™ˆíŽ˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        router.push('/')
        return
      }

      if (!response.ok) {
        throw new Error('Failed to update rating')
      }
    } catch (error) {
      console.error('Error updating dislike:', error)
      // ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
      setDislikedMessages((prev) => {
        const newSet = new Set(prev)
        if (isCurrentlyDisliked) {
          newSet.add(messageId)
        } else {
          newSet.delete(messageId)
        }
        return newSet
      })
    }
  }, [chatId, dislikedMessages, router])

  const handleEditMessage = useCallback((messageId: string, content: string) => {
    setEditingMessageId(messageId)
    setEditingContent(content)
    setSelectedMessageId(null)
  }, [])

  const handleSaveEdit = (messageId: string) => {
    // ë©”ì‹œì§€ ë‚´ìš© ì—…ë°ì´íŠ¸
    const updatedMessages = messages.map((msg) => 
      msg.id === messageId ? { ...msg, content: editingContent } : msg
    )
    setMessages(updatedMessages)
    
    // íŽ¸ì§‘ ìƒíƒœ ì´ˆê¸°í™”
    setEditingMessageId(null)
    const savedContent = editingContent
    setEditingContent("")

    // íŽ¸ì§‘ëœ ì‚¬ìš©ìž ë©”ì‹œì§€ì¸ ê²½ìš° í•´ë‹¹ ë©”ì‹œì§€ ì´í›„ ëª¨ë“  ë©”ì‹œì§€ ì‚­ì œí•˜ê³  ìž¬ìƒì„±
    const messageIndex = messages.findIndex((msg) => msg.id === messageId)
    const editedMessage = messages[messageIndex]
    
    if (editedMessage && editedMessage.role === "user" && selectedModel && chatId && session?.user?.email) {
      // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
      if (isStreaming) {
        handleAbort()
      }
      
      // í•´ë‹¹ ì‚¬ìš©ìž ë©”ì‹œì§€ì— ëŒ€í•´ ìž¬ìƒì„± ìƒíƒœ ì„¤ì •
      setRegeneratingMessageId(messageId)
      
      // í•´ë‹¹ ì‚¬ìš©ìž ë©”ì‹œì§€ ì´í›„ì˜ ëª¨ë“  ë©”ì‹œì§€ ì œê±° (íŽ¸ì§‘ëœ ì‚¬ìš©ìž ë©”ì‹œì§€ëŠ” ìœ ì§€)
      setTimeout(() => {
        setMessages(prev => prev.slice(0, messageIndex + 1))
        
        // ìŠ¤í¬ë¡¤ì„ í˜„ìž¬ ìœ„ì¹˜ë¡œ ì´ë™
        setTimeout(() => scrollToBottomSmooth(), 100)

        // íŽ¸ì§‘ëœ ë‚´ìš©ìœ¼ë¡œ AI ìž¬ìƒì„±
        setTimeout(() => {
          // ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì´ˆê¸°í™”
          streamingInProgress.current = false
          sessionStorage.removeItem(`lastMessage_${chatId}`)
          lastSubmittedMessage.current = null
          lastSubmittedTime.current = 0
          
          sendMessageToAI(savedContent, {
            id: selectedModel.id,
            type: selectedModel.type
          }, true)
        }, 300)
      }, 100) // ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ í›„ ìž ì‹œ ëŒ€ê¸°
    }
  }

  const handleCancelEdit = useCallback(() => {
    setEditingMessageId(null)
    setEditingContent("")
  }, [])

  const handleRegenerateResponse = (messageId: string) => {
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
    if (isStreaming) {
      handleAbort()
    }
    
    // í•´ë‹¹ AI ì‘ë‹µ ë©”ì‹œì§€ì™€ ê·¸ ì´í›„ì˜ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  ë‹¤ì‹œ ìƒì„±
    const messageIndex = messages.findIndex((msg) => msg.id === messageId)
    if (messageIndex > 0 && selectedModel && chatId && session?.user?.email) {
      const previousUserMessage = messages[messageIndex - 1]
      if (previousUserMessage.role === "user") {
        // í•´ë‹¹ ì‚¬ìš©ìž ë©”ì‹œì§€ì— ëŒ€í•´ ìž¬ìƒì„± ìƒíƒœ ì„¤ì •
        setRegeneratingMessageId(previousUserMessage.id)
        
        // í•´ë‹¹ AI ì‘ë‹µ ë©”ì‹œì§€ë¶€í„° ëª¨ë“  ë©”ì‹œì§€ ì œê±° (ì‚¬ìš©ìž ë©”ì‹œì§€ëŠ” ìœ ì§€)
        setMessages(messages.slice(0, messageIndex))
        
        // ìŠ¤í¬ë¡¤ì„ í˜„ìž¬ ìœ„ì¹˜ë¡œ ì´ë™
        setTimeout(() => scrollToBottomSmooth(), 100)

        // ìž¬ìƒì„±ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™” ë° AI ìš”ì²­
        setTimeout(() => {
          // ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì´ˆê¸°í™”
          streamingInProgress.current = false
          sessionStorage.removeItem(`lastMessage_${chatId}`)
          lastSubmittedMessage.current = null
          lastSubmittedTime.current = 0
          
          sendMessageToAI(previousUserMessage.content, {
            id: selectedModel.id,
            type: selectedModel.type
          }, true)
        }, 300) // ì¤‘ë‹¨ ì²˜ë¦¬ ì™„ë£Œë¥¼ ìœ„í•´ ì§§ì€ ì§€ì—°
      }
    }
  }

  const handleRegenerateFromUserMessage = async (messageId: string) => {
    console.log('=== handleRegenerateFromUserMessage called ===')
    console.log('messageId:', messageId)
    console.log('isStreaming:', isStreaming)
    console.log('regeneratingMessageId:', regeneratingMessageId)
    
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
    if (isStreaming) {
      handleAbort()
    }
    
    // í•´ë‹¹ ì‚¬ìš©ìž ë©”ì‹œì§€ë¶€í„° í•˜ìœ„ ëª¨ë“  ë©”ì‹œì§€ ì œê±°í•˜ê³  ë‹¤ì‹œ ìƒì„±
    const messageIndex = messages.findIndex((msg) => msg.id === messageId)
    if (messageIndex >= 0 && selectedModel && chatId && session?.user?.email) {
      const userMessage = messages[messageIndex]
      if (userMessage.role === "user") {
        // í•´ë‹¹ ì‚¬ìš©ìž ë©”ì‹œì§€ì— ëŒ€í•´ ìž¬ìƒì„± ìƒíƒœ ì„¤ì •
        console.log('Setting regeneratingMessageId to:', messageId)
        setRegeneratingMessageId(messageId)
        
        // ì‚¬ìš©ìž ë©”ì‹œì§€ ë‹¤ìŒë¶€í„°ì˜ ëª¨ë“  ë©”ì‹œì§€ê°€ ìžˆëŠ”ì§€ í™•ì¸
        const nextMessageIndex = messageIndex + 1
        if (nextMessageIndex < messages.length) {
          const nextMessage = messages[nextMessageIndex]
          
          try {
            console.log('=== Attempting to delete messages from database ===');
            console.log('nextMessage.id:', nextMessage.id);
            console.log('chatId:', chatId);
            console.log('session.user.email:', session.user.email);
            
            // ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í•´ë‹¹ ë©”ì‹œì§€ë¶€í„° ì´í›„ ëª¨ë“  ë©”ì‹œì§€ ì‚­ì œ
            const response = await fetch(`/api/chat/${chatId}?userId=${session.user.email}&fromMessageId=${nextMessage.id}`, {
              method: 'DELETE'
            })
            
            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              console.error('Delete API response not ok:', response.status, errorData);
              throw new Error(`Failed to delete messages from database: ${response.status} ${errorData.error || response.statusText}`);
            }
            
            const deleteResult = await response.json();
            console.log('Delete operation successful:', deleteResult);
            
            if (deleteResult.success) {
              console.log(`Successfully deleted ${deleteResult.deletedCount} messages from database`);
              console.log(`Remaining messages in database: ${deleteResult.remainingCount}`);
              
              // ì‚­ì œ ìž‘ì—…ì´ ì™„ë£Œëœ í›„ ì‹¤ì œë¡œ ë©”ì‹œì§€ê°€ ì‚­ì œë˜ì—ˆëŠ”ì§€ ê²€ì¦
              if (deleteResult.deletedCount > 0) {
                console.log('=== Verifying deletion by reloading chat history ===');
                
                // ìž ì‹œ í›„ ì±„íŒ… ê¸°ë¡ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ì‚­ì œê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                setTimeout(async () => {
                  try {
                    const verifyResponse = await fetch(`/api/chat/${chatId}`);
                    if (verifyResponse.ok) {
                      const verifyData = await verifyResponse.json();
                      const currentMessages = verifyData.messages || [];
                      
                      console.log('Verification: Current messages in database:', currentMessages.length);
                      
                      // ì‚­ì œëœ ë©”ì‹œì§€ê°€ ì—¬ì „ížˆ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸
                      const deletedMessageStillExists = currentMessages.some((msg: any) => msg.id === nextMessage.id);
                      
                      if (deletedMessageStillExists) {
                        console.error('ERROR: Deleted message still exists in database!');
                        console.error('This may cause the regeneration issue on page refresh');
                      } else {
                        console.log('âœ“ Verification successful: Messages properly deleted from database');
                      }
                    }
                  } catch (verifyError) {
                    console.error('Failed to verify deletion:', verifyError);
                  }
                }, 1000);
              }
            } else {
              console.warn('Delete operation reported failure:', deleteResult);
            }
          } catch (error) {
            console.error('Error deleting messages from database:', error);
            
            // ì‚¬ìš©ìžì—ê²Œ ì—ëŸ¬ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
            if (error instanceof Error && error.message.includes('Failed to delete messages')) {
              console.warn('Database deletion failed, but continuing with UI update');
              // ì—¬ê¸°ì„œ ì‚¬ìš©ìžì—ê²Œ ì•Œë¦¼ì„ í‘œì‹œí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤
              // alert('ì¼ë¶€ ë©”ì‹œì§€ ì‚­ì œì— ì‹¤íŒ¨í–ˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.');
            }
            
            // ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨í•´ë„ UIì—ì„œëŠ” ì§„í–‰
            console.log('Continuing with regeneration despite database deletion error');
          }
        } else {
          console.log('No messages to delete after current user message');
        }
        
        // í•´ë‹¹ ì‚¬ìš©ìž ë©”ì‹œì§€ ì´í›„ì˜ ëª¨ë“  ë©”ì‹œì§€ ì œê±° (ì‚¬ìš©ìž ë©”ì‹œì§€ëŠ” ìœ ì§€)
        setMessages(messages.slice(0, messageIndex + 1))
        
        // ìŠ¤í¬ë¡¤ì„ í˜„ìž¬ ìœ„ì¹˜ë¡œ ì´ë™
        setTimeout(() => scrollToBottomSmooth(), 100)

        // ìž¬ìƒì„±ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™” ë° AI ìš”ì²­
        setTimeout(async () => {
          console.log('=== Starting regeneration process ===')
          console.log('selectedModel:', selectedModel)
          console.log('chatId:', chatId)
          console.log('session?.user?.email:', session?.user?.email)
          
          // ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì´ˆê¸°í™”
          streamingInProgress.current = false
          sessionStorage.removeItem(`lastMessage_${chatId}`)
          lastSubmittedMessage.current = null
          lastSubmittedTime.current = 0
          
          // ì‚¬ìš©ìž ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
          let messageContent = userMessage.content
          let imagesToSend: File[] = []
          
          try {
            // JSON í˜•íƒœë¡œ ì €ìž¥ëœ ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
            const parsed = JSON.parse(userMessage.content)
            if (parsed.hasImages && parsed.images && Array.isArray(parsed.images)) {
              messageContent = parsed.text || ''
              // Base64 ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
              imagesToSend = await Promise.all(
                parsed.images.map(async (imageInfo: any) => {
                  if (imageInfo.data) {
                    // Base64 ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
                    const response = await fetch(imageInfo.data)
                    const blob = await response.blob()
                    // Blobì„ File ê°ì²´ë¡œ ë³€í™˜
                    return new File([blob], imageInfo.name || 'image.png', { 
                      type: imageInfo.mimeType || 'image/png' 
                    })
                  }
                  return null
                })
              ).then(files => files.filter(file => file !== null) as File[])
            }
          } catch (e) {
            // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
            messageContent = userMessage.content
          }
          
          console.log('=== Calling sendMessageToAI ===')
          console.log('messageContent:', messageContent)
          console.log('agentInfo:', { id: selectedModel.id, type: selectedModel.type })
          console.log('isRegeneration:', true)
          console.log('imagesToSend:', imagesToSend)
          
          try {
            await sendMessageToAI(messageContent, {
              id: selectedModel.id,
              type: selectedModel.type
            }, true, imagesToSend)
            console.log('=== Regeneration sendMessageToAI completed ===')
          } catch (error) {
            console.error('Error in sendMessageToAI during regeneration:', error)
            // ìž¬ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ ìƒíƒœ ë¦¬ì…‹
            console.log('Resetting regeneration state due to error in regeneration')
            setRegeneratingMessageId(null)
            setIsStreaming(false)
            streamingInProgress.current = false
          }
        }, 300) // ì¤‘ë‹¨ ì²˜ë¦¬ ì™„ë£Œë¥¼ ìœ„í•´ ì§§ì€ ì§€ì—°
      }
    }
  }

  const handleSubmit = useCallback(async () => {
    // ì´ë¯¸ ì „ì†¡ ì¤‘ì¸ ê²½ìš° ì°¨ë‹¨ (ì´ì¤‘ ì²´í¬)
    if (isSubmitting || isSubmittingRef.current) {
      console.log('Already submitting, preventing duplicate')
      return
    }
    
    // ì¤‘ë³µ ë©”ì‹œì§€ ê²€ì‚¬ (ê°™ì€ ë©”ì‹œì§€ê°€ 500ms ì´ë‚´ì— ì „ì†¡ë˜ëŠ” ê²½ìš°)
    const currentTime = Date.now()
    const messageToCheck = inputValue.trim() || 'IMAGE_ONLY'
    
    if (lastSubmittedMessage.current === messageToCheck && 
        currentTime - lastSubmittedTime.current < 500) {
      console.log('Duplicate message detected, preventing submission')
      return
    }
    
    // ë¹ˆ ë©”ì‹œì§€ ì²´í¬ (í…ìŠ¤íŠ¸ë„ ì—†ê³  ì´ë¯¸ì§€ë„ ì—†ëŠ” ê²½ìš°)
    if (!inputValue.trim() && uploadedImages.length === 0) {
      console.log('Empty message, preventing submission')
      return
    }
    
    // ì „ì†¡ ì‹œìž‘ í”Œëž˜ê·¸ ì„¤ì •
    isSubmittingRef.current = true
    
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì´ë©´ ë¨¼ì € ì¤‘ë‹¨
    if (isStreaming) {
      handleAbort()
    }
    
    if ((inputValue.trim() || uploadedImages.length > 0) && selectedModel && chatId && session?.user?.email) {
      try {
        // ì „ì†¡ ì¤‘ í”Œëž˜ê·¸ ì„¤ì •
        setIsSubmitting(true)
        
        // ìƒˆ ë©”ì‹œì§€ ì „ì†¡ ì‹œ ìž¬ìƒì„± ìƒíƒœ ë¦¬ì…‹
        console.log('New message submission - resetting regeneration state')
        setRegeneratingMessageId(null)
        
        // ì¤‘ë³µ ë°©ì§€ ì •ë³´ ì—…ë°ì´íŠ¸
        lastSubmittedMessage.current = messageToCheck
        lastSubmittedTime.current = currentTime
      
      // ì „ì†¡í•  ì´ë¯¸ì§€ì™€ ë©”ì‹œì§€ ì½˜í…ì¸  ì¤€ë¹„
      const imagesToSend = [...uploadedImages]
      const messageContent = inputValue
      
      // ì‚¬ìš©ìž ë©”ì‹œì§€ ì½˜í…ì¸  ìƒì„± (ì´ë¯¸ì§€ ì •ë³´ í¬í•¨)
      let userMessageContent = inputValue || ''
      
      // ì´ë¯¸ì§€ê°€ ìžˆëŠ” ê²½ìš° JSON í˜•íƒœë¡œ ì €ìž¥ (UserRequestì—ì„œ íŒŒì‹±í•˜ì—¬ í‘œì‹œ)
      if (imagesToSend.length > 0) {
        const imageInfos = await Promise.all(
          imagesToSend.map(async (image) => {
            // ì‚¬ìš©ìž ë©”ì‹œì§€ í‘œì‹œë¥¼ ìœ„í•´ base64 ë°ì´í„°ë„ í¬í•¨
            const reader = new FileReader()
            const base64 = await new Promise<string>((resolve) => {
              reader.onload = (e) => resolve(e.target?.result as string)
              reader.readAsDataURL(image)
            })
            
            return {
              type: 'image',
              name: image.name,
              size: image.size,
              mimeType: image.type,
              data: base64
            }
          })
        )
        
        userMessageContent = JSON.stringify({
          text: inputValue || '',
          images: imageInfos,
          hasImages: true
        })
      }

      // ë©”ì‹œì§€ ì¶”ê°€ (ì´ë¯¸ì§€ ì •ë³´ í¬í•¨)
      const newUserMessage: Message = {
        id: generateUniqueId("user"),
        role: "user",
        content: userMessageContent,
        timestamp: new Date(),
      }

      // ìƒˆ ë©”ì‹œì§€ ID ì¶”ê°€
      setNewMessageIds(prev => new Set([...prev, newUserMessage.id]))
      setMessages([...messages, newUserMessage])
      
      // ìž…ë ¥ ìƒíƒœ ì´ˆê¸°í™”
      setInputValue("")
      setUploadedImages([]) // ì´ë¯¸ì§€ ìƒíƒœ ì´ˆê¸°í™”
      
      // ChatInputì˜ ì´ë¯¸ì§€ë„ ì´ˆê¸°í™”
      setClearImagesTrigger(prev => !prev)
      
      // í…ìŠ¤íŠ¸ ìž…ë ¥ì°½ ê°•ì œ ì´ˆê¸°í™” (í•œê¸€ IME ì¡°í•© ì¤‘ì¸ ê¸€ìž ì œê±°)
      // IME ì¡°í•© ì™„ë£Œë¥¼ ìœ„í•´ ì•½ê°„ì˜ ì§€ì—° í›„ ì´ˆê¸°í™”
      setTimeout(() => {
        if (textareaRef.current) {
          textareaRef.current.value = ""
          textareaRef.current.style.height = "auto"
          textareaRef.current.style.height = "52px"
          
          // React ìƒíƒœì™€ ë™ê¸°í™”
          setInputValue("")
        }
      }, 0)
      
      // ë©”ì‹œì§€ ì¶”ê°€ í›„ ì¦‰ì‹œ ìŠ¤í¬ë¡¤
      scrollToBottomSmooth()

      // ìŠ¤íŠ¸ë¦¬ë°ì´ ì¤‘ë‹¨ë˜ì—ˆë‹¤ë©´ ìž ì‹œ ëŒ€ê¸° í›„ ìƒˆ ë©”ì‹œì§€ ì „ì†¡
      const sendMessage = () => {
        sendMessageToAI(messageContent, {
          id: selectedModel.id,
          type: selectedModel.type
        }, false, imagesToSend).finally(() => {
          // ì „ì†¡ ì™„ë£Œ í›„ í”Œëž˜ê·¸ í•´ì œ
          setIsSubmitting(false)
          isSubmittingRef.current = false
        })
      }
      
        if (isStreaming) {
          // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì²˜ë¦¬ ì™„ë£Œë¥¼ ìœ„í•´ ì§§ì€ ì§€ì—° í›„ ì „ì†¡
          setTimeout(sendMessage, 100)
        } else {
          // ì¦‰ì‹œ ì „ì†¡
          sendMessage()
        }
      } catch (error) {
        console.error('Error in handleSubmit:', error)
        // ì—ëŸ¬ ë°œìƒ ì‹œ í”Œëž˜ê·¸ í•´ì œ
        setIsSubmitting(false)
        isSubmittingRef.current = false
      }
    }
  }, [inputValue, uploadedImages, messages, selectedModel, chatId, session?.user?.email, isStreaming, isSubmitting, generateUniqueId, scrollToBottomSmooth, sendMessageToAI, handleAbort])

  const handleKeyDown = useCallback((e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === "Shift") {
      setIsShiftPressed(true)
    }

    if (e.key === "Enter") {
      if (e.shiftKey) {
        // Shift + Enter: ì¤„ë°”ê¿ˆ í—ˆìš© (ê¸°ë³¸ ë™ìž‘)
        return
      } else {
        // Enterë§Œ ëˆ„ë¥´ë©´ submit ë™ìž‘
        e.preventDefault()
        
        // IME ì¡°í•© ì¤‘ì¸ì§€ í™•ì¸
        if (e.nativeEvent.isComposing || isComposing) {
          // ì¡°í•© ì¤‘ì´ë©´ ìž ì‹œ ëŒ€ê¸°
          return
        }
        
        // ì¦‰ì‹œ ì‹¤í–‰ (setTimeout ì œê±°ë¡œ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
        handleSubmit()
      }
    }
  }, [handleSubmit, isComposing])

  // ë©”ì‹œì§€ ë Œë”ë§ì„ ì¡°ê±´ë¶€ ë Œë”ë§ ë°–ì—ì„œ ì •ì˜í•˜ì—¬ Hook ìˆœì„œ ìœ ì§€
  const renderedMessages = useMemo(() => {
    console.log('=== Rendering messages ===')
    console.log('messages.length:', messages.length)
    console.log('historyLoaded:', historyLoaded)
    console.log('showSkeleton:', showSkeleton)
    console.log('regeneratingMessageId:', regeneratingMessageId)
    console.log('isStreaming:', isStreaming)
    
    return messages.map((message, index) => (
      <MessageWrapper
        key={`${message.id}-${forceUpdateCounter}-${regeneratingMessageId || 'none'}`}
        message={message}
        isNewMessage={newMessageIds.has(message.id)}
        copiedMessageId={copiedMessageId}
        likedMessages={likedMessages}
        dislikedMessages={dislikedMessages}
        isStreaming={isStreaming}
        editingMessageId={editingMessageId}
        editingContent={editingContent}
        regeneratingMessageId={regeneratingMessageId}
        streamingMessageId={streamingMessageId}
        onCopy={handleCopyMessage}
        onLike={handleLikeMessage}
        onDislike={handleDislikeMessage}
        onRegenerate={handleRegenerateResponse}
        onEdit={handleEditMessage}
        onSave={handleSaveEdit}
        onCancel={handleCancelEdit}
        onRegenerateFromUser={handleRegenerateFromUserMessage}
        setEditingContent={setEditingContent}
      />
    ))
  }, [messages, newMessageIds, copiedMessageId, likedMessages, dislikedMessages, isStreaming, editingMessageId, editingContent, regeneratingMessageId, streamingMessageId, forceUpdateCounter]
  )

  // ì¸ì¦ë˜ì§€ ì•Šì€ ê²½ìš° ë¦¬ë‹¤ì´ë ‰íŠ¸
  if (sessionStatus === "unauthenticated") {
    router.push('/auth')
    return null
  }

  return (
    <>
      {/* ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ */}
      <div className="flex-1 flex flex-col px-3 sm:px-0 relative overflow-hidden">
        <div 
          ref={messagesContainerRef}
          className="messages-container flex-1 overflow-y-auto p-3 sm:p-4 md:p-6 transition-all duration-200 ease-out mobile-scroll touch-scroll"
          style={{ 
            scrollBehavior: 'smooth',
            paddingBottom: `${dynamicPadding}px`,
            overflowAnchor: 'none'
          }}
        >
          <div className="sm:px-3 max-w-full sm:max-w-2xl md:max-w-3xl lg:max-w-4xl mx-auto">
            {(() => {
              console.log('=== Render condition check ===')
              console.log('!historyLoaded && showSkeleton:', !historyLoaded && showSkeleton)
              console.log('!historyLoaded && !showSkeleton:', !historyLoaded && !showSkeleton)
              console.log('else (should render messages):', historyLoaded)
              console.log('renderedMessages length:', renderedMessages.length)
              
              if (!historyLoaded && showSkeleton) {
                console.log('Rendering skeleton')
                return <ChatMessageSkeleton />
              } else if (!historyLoaded && !showSkeleton) {
                console.log('Rendering empty div')
                return <div></div>
              } else {
                console.log('Rendering messages')
                return renderedMessages
              }
            })()}
            <div ref={messagesEndRef} className="h-4" />
          </div>
        </div>

        {/* ìž…ë ¥ ì»¨í…Œì´ë„ˆ - ë‹¨ ê³ ì • */}
          <ChatInput
            inputValue={inputValue}
            textareaRef={textareaRef}
            isGlobeActive={isGlobeActive}
            isDeepResearchActive={isDeepResearchActive}
            isStreaming={isStreaming}
            isSubmitting={isSubmitting}
            handleInputChange={handleInputChange}
            handleKeyDown={handleKeyDown}
            handleKeyUp={handleKeyUp}
            handleCompositionStart={handleCompositionStart}
            handleCompositionEnd={handleCompositionEnd}
            handleSubmit={handleSubmit}
            handleAbort={handleAbort}
            setIsGlobeActive={setIsGlobeActive}
            setIsDeepResearchActive={setIsDeepResearchActive}
            onImageUpload={handleImageUpload}
            clearImages={clearImagesTrigger}
            supportsMultimodal={supportsMultimodal}
            selectedAgent={selectedModel?.type === 'agent' ? selectedModel : null}
          />
      </div>
    </>
  )
}
