import { BaseLLM } from "./base";
import { LLMMessage, LLMResponse } from "./types";

export interface DeepResearchStep {
  id: string;
  title: string;
  question: string;
  analysis: string;
  sources?: string[];
  confidence: number;
}

export interface DeepResearchResult {
  query: string;
  steps: DeepResearchStep[];
  synthesis: string;
  finalAnswer: string;
  confidence: number;
  methodology: string;
}

export interface DeepResearchConfig {
  maxSteps: number;
  confidenceThreshold: number;
  analysisDepth: 'basic' | 'intermediate' | 'advanced';
  includeSourceCitations: boolean;
  language: 'ko' | 'en';
}

export class DeepResearchProcessor {
  private llm: BaseLLM;
  private config: DeepResearchConfig;

  constructor(llm: BaseLLM, config: Partial<DeepResearchConfig> = {}) {
    this.llm = llm;
    this.config = {
      maxSteps: 5,
      confidenceThreshold: 0.8,
      analysisDepth: 'intermediate',
      includeSourceCitations: false,
      language: 'ko',
      ...config
    };
  }

  /**
   * ë”¥ë¦¬ì„œì¹˜ ìˆ˜í–‰ - ê°œì„ ëœ êµ¬ì¡°
   */
  async performDeepResearch(
    query: string,
    context: string = "",
    onProgress?: (step: DeepResearchStep) => void,
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void
  ): Promise<DeepResearchResult> {
    try {
      console.log('=== Deep Research Started ===');
      console.log('Query:', query);
      
      // 1ë‹¨ê³„: Sub-questions ìƒì„± ë° ì¦‰ì‹œ í‘œì‹œ
      console.log('1. Generating and displaying sub-questions...');
      const subQuestions = await this.generateSubQuestions(query, context);
      console.log('Sub-questions generated:', subQuestions);
      
      // ê³„íšëœ ìŠ¤íƒ­ë“¤ì„ ë¯¸ë¦¬ ì „ë‹¬ (sub-questionsë¥¼ ë¨¼ì € í‘œì‹œ)
      const plannedSteps = [
        { title: 'Sub-questions Generated', type: 'step' },
        { title: 'Question Analysis', type: 'step' },
        ...subQuestions.map(q => ({ title: `Analysis: ${q}`, type: 'step' })),
        { title: 'Synthesis Analysis', type: 'synthesis' },
        { title: 'Final Answer', type: 'final' }
      ];

      console.log('2. Sending planned steps:', plannedSteps);
      if (onStream) {
        onStream('Deep research plan has been established.', 'step', { 
          title: 'Analysis Planning', 
          isComplete: true,
          totalSteps: plannedSteps.length,
          plannedSteps: plannedSteps
        } as any);
      }

      // 1.5. Sub-questions ì¦‰ì‹œ í‘œì‹œ
      console.log('1.5. Displaying sub-questions immediately...');
      if (onStream) {
        const subQuestionsContent = `## [Analysis Start] Sub-questions Generated

### ğŸ¯ Generated Sub-questions
ë‹¤ìŒê³¼ ê°™ì€ ì„¸ë¶€ ì§ˆë¬¸ë“¤ì„ ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤:

${subQuestions.map((q, i) => `**${i + 1}. ${q}**`).join('\n\n')}

### ğŸ“‹ Analysis Plan
ê° ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.

### ğŸ” Analysis Methodology
- ê° ì„¸ë¶€ ì§ˆë¬¸ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ìˆ˜í–‰
- ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì ‘ê·¼
- ì´ì „ ë¶„ì„ ê²°ê³¼ì™€ì˜ ì—°ê´€ì„± ê²€í† 
- ì¢…í•©ì ì¸ ê²°ë¡  ë„ì¶œ`;
        
        onStream(subQuestionsContent, 'step', { 
          title: 'Sub-questions Generated', 
          isComplete: true
        });
      }

      // 2ë‹¨ê³„: ì´ˆê¸° ì§ˆë¬¸ ë¶„ì„
      console.log('3. Starting initial query analysis...');
      const analysisStep = await this.analyzeQuery(query, context, onStream);
      console.log('Initial analysis completed:', analysisStep.title);

      // 3ë‹¨ê³„: ê° Sub-question ë¶„ì„ (ê°œë³„ ì»´í¬ë„ŒíŠ¸ì— ë§¤í•‘)
      const steps = [analysisStep];
      
      console.log('4. Starting sub-question analysis...');
      for (let i = 0; i < Math.min(subQuestions.length, this.config.maxSteps - 1); i++) {
        const subQuestion = subQuestions[i];
        const plannedTitle = `Analysis: ${subQuestion}`;
        console.log(`4.${i+1}. Analyzing sub-question: ${plannedTitle}`);
        const step = await this.analyzeSubQuestion(subQuestion, context, steps, onStream, plannedTitle);
        steps.push(step);
        console.log(`4.${i+1}. Sub-question analysis completed`);
      }

      // 4ë‹¨ê³„: ì¢…í•© ë¶„ì„
      console.log('5. Starting synthesis...');
      const synthesis = await this.synthesizeFindings(query, steps, onStream);
      console.log('Synthesis completed');
      
      // 5ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±
      console.log('6. Generating final answer...');
      const finalAnswer = await this.generateFinalAnswer(query, steps, synthesis, onStream);
      console.log('Final answer generated');

      console.log('=== Deep Research Completed ===');
      return {
        query,
        steps,
        synthesis,
        finalAnswer,
        confidence: this.calculateOverallConfidence(steps),
        methodology: this.generateMethodologyDescription()
      };

    } catch (error) {
      console.error('Deep research error:', error);
      throw new Error(`Error occurred during deep research: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * ë‹¨ê³„ë³„ ë”¥ë¦¬ì„œì¹˜ ìˆ˜í–‰ - 1ë‹¨ê³„: Sub-questions ìƒì„±
   */
  async generateSubQuestionsStep(
    query: string,
    context: string = ""
  ): Promise<{ subQuestions: string[], plannedSteps: Array<{ title: string, type: string }> }> {
    console.log('=== Step 1: Generating Sub-questions ===');
    
    const subQuestions = await this.generateSubQuestions(query, context);
    console.log('Sub-questions generated:', subQuestions);
    
    const plannedSteps = [
      { title: 'Sub-questions Generated', type: 'step' },
      { title: 'Question Analysis', type: 'step' },
      ...subQuestions.map(q => ({ title: `Analysis: ${q}`, type: 'step' })),
      { title: 'Synthesis Analysis', type: 'synthesis' },
      { title: 'Final Answer', type: 'final' }
    ];

    return { subQuestions, plannedSteps };
  }

  /**
   * ë‹¨ê³„ë³„ ë”¥ë¦¬ì„œì¹˜ ìˆ˜í–‰ - 2ë‹¨ê³„: ì´ˆê¸° ì§ˆë¬¸ ë¶„ì„
   */
  async analyzeQueryStep(
    query: string,
    context: string = "",
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void
  ): Promise<DeepResearchStep> {
    console.log('=== Step 2: Analyzing Query ===');
    return await this.analyzeQuery(query, context, onStream);
  }

  /**
   * ë‹¨ê³„ë³„ ë”¥ë¦¬ì„œì¹˜ ìˆ˜í–‰ - 3ë‹¨ê³„: ê°œë³„ Sub-question ë¶„ì„
   */
  async analyzeSubQuestionStep(
    subQuestion: string,
    query: string,
    context: string = "",
    previousSteps: DeepResearchStep[] = [],
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void
  ): Promise<DeepResearchStep> {
    console.log('=== Step 3: Analyzing Sub-question ===');
    const plannedTitle = `Analysis: ${subQuestion}`;
    return await this.analyzeSubQuestion(subQuestion, context, previousSteps, onStream, plannedTitle);
  }

  /**
   * ë‹¨ê³„ë³„ ë”¥ë¦¬ì„œì¹˜ ìˆ˜í–‰ - 4ë‹¨ê³„: ì¢…í•© ë¶„ì„
   */
  async synthesizeStep(
    query: string,
    steps: DeepResearchStep[],
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void
  ): Promise<string> {
    console.log('=== Step 4: Synthesizing Findings ===');
    return await this.synthesizeFindings(query, steps, onStream);
  }

  /**
   * ë‹¨ê³„ë³„ ë”¥ë¦¬ì„œì¹˜ ìˆ˜í–‰ - 5ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±
   */
  async generateFinalAnswerStep(
    query: string,
    steps: DeepResearchStep[],
    synthesis: string,
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void
  ): Promise<string> {
    console.log('=== Step 5: Generating Final Answer ===');
    return await this.generateFinalAnswer(query, steps, synthesis, onStream);
  }

  /**
   * ì´ˆê¸° ì§ˆë¬¸ ë¶„ì„
   */
  private async analyzeQuery(query: string, context: string, onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void): Promise<DeepResearchStep> {
    console.log('analyzeQuery started');
    
    const prompt = `Please analyze the following question systematically. Detect the language of the input and respond in the same language. Do not use markdown formatting or emojis in your response.

Question: "${query}"
${context ? `Context: ${context}` : ''}

Please analyze using the following structure without markdown headers:

[Analysis Start] Question Analysis

Core Concept Definition:
- Define the core keywords and concepts of the question

Question Intent Analysis:
- Explain what the questioner wants to know fundamentally

Analysis Perspective Setting:
- List the various perspectives needed to solve this question

Analysis Methodology:
- Present a systematic approach to this question

Expected Complexity and Difficulty:
- Evaluate the complexity and analysis difficulty of this question

Please perform systematic and in-depth analysis without using markdown formatting.`;

    const messages: LLMMessage[] = [
      { role: "system", content: this.getSystemPrompt() },
      { role: "user", content: prompt }
    ];

    console.log('Sending start signal for Question Analysis');
    // ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì „ì†¡ (ìƒíƒœë§Œ)
    if (onStream) {
      onStream('', 'step', { title: 'Question Analysis', isComplete: false });
    }

    console.log('Calling LLM for analysis...');
    const response = await this.llm.chat(messages);
    console.log('LLM response received, length:', response.content.length);
    
    console.log('Sending completion signal for Question Analysis');
    // ì™„ë£Œ í›„ ê²°ê³¼ ì „ì†¡
    if (onStream) {
      onStream(response.content, 'step', { title: 'Question Analysis', isComplete: true });
    }
    
    console.log('analyzeQuery completed');
    return {
      id: `step-analysis-${Date.now()}`,
      title: "Question Analysis",
      question: query,
      analysis: response.content,
      confidence: 0.8
    };
  }

  /**
   * í•˜ìœ„ ì§ˆë¬¸ ìƒì„± - ê°œì„ ëœ ì¶”ì¶œ ë¡œì§
   */
  private async generateSubQuestions(query: string, context: string): Promise<string[]> {
    const prompt = `Generate 3-4 sub-questions to deeply analyze the following question. Detect the language of the input and respond in the same language. Do not use markdown formatting or emojis in your response.

Question: "${query}"
${context ? `Context: ${context}` : ''}

Create sub-questions from each of the following perspectives:
- Core concept analysis
- Multi-perspective exploration
- Specific case studies
- Impact and outcome analysis

Please list them in exactly the following format without any formatting:
1. [Question content]
2. [Question content]
3. [Question content]
4. [Question content]`;

    const messages: LLMMessage[] = [
      { role: "system", content: this.getSystemPrompt() },
      { role: "user", content: prompt }
    ];

    const response = await this.llm.chat(messages);
    
    // ì‘ë‹µì—ì„œ ì§ˆë¬¸ë“¤ ì¶”ì¶œ - ë” ê²¬ê³ í•œ ë¡œì§
    const questions = response.content
      .split('\n')
      .filter(line => line.trim().length > 0)
      .map(line => line.trim())
      .filter(line => /^\d+[.)]\s*/.test(line)) // ìˆ«ì + ì  ë˜ëŠ” ê´„í˜¸ íŒ¨í„´
      .map(line => line.replace(/^\d+[.)]\s*/, '').trim()) // ë²ˆí˜¸ ì œê±°
      .filter(q => q.length > 0 && q.length < 200); // ë¹ˆ ë¬¸ìì—´ ë° ë„ˆë¬´ ê¸´ ë¬¸ìì—´ ì œê±°

    console.log('Generated sub-questions:', questions);
    return questions.slice(0, 4); // ìµœëŒ€ 4ê°œ ì§ˆë¬¸
  }

  /**
   * í•˜ìœ„ ì§ˆë¬¸ ë¶„ì„ - ì •í™•í•œ ì œëª© ë§¤ì¹­
   */
  private async analyzeSubQuestion(
    question: string, 
    context: string, 
    previousSteps: DeepResearchStep[],
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void,
    plannedTitle?: string
  ): Promise<DeepResearchStep> {
    const previousContext = previousSteps
      .map(step => `${step.title}: ${step.analysis}`)
      .join('\n\n');

    const prompt = `Please analyze the following sub-question systematically. Detect the language of the input and respond in the same language. Do not use markdown formatting or emojis in your response.

Question: "${question}"
${context ? `Original Context: ${context}` : ''}

Previous Analysis Results:
${previousContext}

Please analyze using the following structure without markdown headers:

[Analysis Start] ${question}

Core Analysis:
- Explain the key points and importance of this question

Detailed Analysis:
- Present specific analysis content and data

Key Findings:
- Summarize the main insights discovered from this analysis

Relationship Analysis:
- Explain the relationship with previous analysis results

Multi-perspective Review:
- Present the results of reviewing from various perspectives

Please perform systematic and in-depth analysis without using markdown formatting.`;

    const messages: LLMMessage[] = [
      { role: "system", content: this.getSystemPrompt() },
      { role: "user", content: prompt }
    ];

    // ê³„íšëœ ì œëª©ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ì œëª© ì‚¬ìš©
    const stepTitle = plannedTitle || `Analysis: ${question}`;

    // ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì „ì†¡ (ìƒíƒœë§Œ)
    if (onStream) {
      onStream('', 'step', { title: stepTitle, isComplete: false });
    }

    const response = await this.llm.chat(messages);
    
    // ì™„ë£Œ í›„ ê²°ê³¼ ì „ì†¡
    if (onStream) {
      onStream(response.content, 'step', { title: stepTitle, isComplete: true });
    }
    
    return {
      id: `step-${Date.now()}`,
      title: stepTitle,
      question,
      analysis: response.content,
      confidence: 0.75
    };
  }

  /**
   * ì¢…í•© ë¶„ì„ ìˆ˜í–‰
   */
  private async synthesizeFindings(query: string, steps: DeepResearchStep[], onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void): Promise<string> {
    const findings = steps
      .map(step => `## ${step.title}\n${step.analysis}`)
      .join('\n\n');

    const prompt = `Please synthesize the multi-perspective analysis results for the question "${query}". Detect the language of the input and respond in the same language. Do not use markdown formatting or emojis in your response.

${findings}

Please perform synthesis analysis using the following structure without markdown headers:

[Analysis Start] Synthesis Analysis

Common Patterns and Themes:
- Organize patterns and themes that commonly appear in multiple analyses

Reconciling Conflicting Perspectives:
- Reconcile and integrate different perspectives

Core Insights:
- Present the core insights derived from the synthesis analysis

Unresolved Questions:
- Identify unresolved questions that require further research

Limitations of Analysis:
- Explain the limitations and constraints of the current analysis

Please perform comprehensive and systematic analysis without using markdown formatting.`;

    const messages: LLMMessage[] = [
      { role: "system", content: this.getSystemPrompt() },
      { role: "user", content: prompt }
    ];

    // ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì „ì†¡ (ìƒíƒœë§Œ)
    if (onStream) {
      onStream('', 'synthesis', { title: 'Synthesis Analysis', isComplete: false });
    }

    const response = await this.llm.chat(messages);
    
    // ì™„ë£Œ í›„ ê²°ê³¼ ì „ì†¡
    if (onStream) {
      onStream(response.content, 'synthesis', { title: 'Synthesis Analysis', isComplete: true });
    }
    
    return response.content;
  }

  /**
   * ìµœì¢… ë‹µë³€ ìƒì„±
   */
  private async generateFinalAnswer(
    query: string, 
    steps: DeepResearchStep[], 
    synthesis: string,
    onStream?: (content: string, type: 'step' | 'synthesis' | 'final', stepInfo?: { title?: string, isComplete?: boolean }) => void
  ): Promise<string> {
    const prompt = `Original Question: "${query}"

Performed Analyses:
${steps.map(step => `- ${step.title}: ${step.analysis}`).join('\n')}

Synthesis Analysis:
${synthesis}

CRITICAL INSTRUCTION - LANGUAGE DETECTION AND RESPONSE:
Please carefully examine the original question "${query}" and detect its language. You must respond in the EXACT SAME LANGUAGE as the original question. This is absolutely critical.

- If the original question is in Korean (í•œêµ­ì–´), respond entirely in Korean
- If the original question is in English, respond entirely in English  
- If the original question is in Japanese (æ—¥æœ¬èª), respond entirely in Japanese
- If the original question is in Chinese (ä¸­æ–‡), respond entirely in Chinese
- For any other language, respond in that detected language

Based on all the analyses above, please provide a comprehensive and in-depth final answer to the original question. Do not use markdown formatting or emojis in your response.

IMPORTANT: When writing the final answer, please follow this format strictly without using markdown headers, and write ALL content in the same language as the original question:

1. First, freely write any analysis process or additional explanations
2. Below write the final answer with the following structure (using appropriate language):
   - Core answer (clear and direct response)
   - Detailed analysis (key perspectives and evidence)  
   - Considerations (limitations, various viewpoints)
   - Conclusion (summary and future directions)

Format example without markdown (adapt section headers to the detected language):

[Analysis process or additional explanations in the original question's language]

Core Answer: (or í•µì‹¬ ë‹µë³€: for Korean, or æ ¸å¿ƒå›ç­”: for Chinese, etc.)
[Content in original language]

Detailed Analysis: (or ìƒì„¸ ë¶„ì„: for Korean, or è©³ç´°åˆ†æ: for Chinese, etc.)
[Content in original language]

Considerations: (or ê³ ë ¤ì‚¬í•­: for Korean, or è€ƒæ…®äº‹é …: for Chinese, etc.)
[Content in original language]

Conclusion: (or ê²°ë¡ : for Korean, or çµè«–: for Chinese, etc.)
[Content in original language]

Remember: The entire response must be in the same language as the original question "${query}".`;

    const messages: LLMMessage[] = [
      { role: "system", content: this.getSystemPrompt() },
      { role: "user", content: prompt }
    ];

    // ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì§„í–‰ ìƒí™© ì „ì†¡ (ìƒíƒœë§Œ)
    if (onStream) {
      onStream('', 'final', { title: 'Final Answer', isComplete: false });
    }

    const response = await this.llm.chat(messages);
    
    // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì „ì²´ ë‚´ìš©ì„ ì „ì†¡í•˜ê³ , ì™„ë£Œ í›„ ê²°ê³¼ì—ì„œë§Œ ë§ˆì»¤ ì¶”ì¶œ
    if (onStream) {
      // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì „ì²´ ë‚´ìš© ì „ì†¡ (ë§ˆì»¤ ì¶”ì¶œ ì—†ì´)
      onStream(response.content, 'final', { title: 'Final Answer', isComplete: true });
    }
    
    // ìµœì¢… ë°˜í™˜ê°’ì—ì„œë§Œ ë§ˆì»¤ ì´í›„ ë¶€ë¶„ ì¶”ì¶œ
    const finalAnswerContent = this.extractFinalAnswerFromResponse(response.content);
    
    return finalAnswerContent;
  }

  /**
   * ì‘ë‹µì—ì„œ ìµœì¢… ë‹µë³€ ì¶”ì¶œ (ë³‘ë ¬ ì²˜ë¦¬ìš© - ë§ˆì»¤ ë¶ˆí•„ìš”)
   */
  private extractFinalAnswerFromResponse(content: string): string {
    // ë³‘ë ¬ ì²˜ë¦¬ì—ì„œëŠ” ë§ˆì»¤ê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì „ì²´ ë‚´ìš© ë°˜í™˜
    console.log('Returning full content as final answer (parallel processing)');
    console.log('Final answer length:', content.length);
    return content;
  }

  /**
   * ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
   */
  private calculateOverallConfidence(steps: DeepResearchStep[]): number {
    if (steps.length === 0) return 0;
    
    const totalConfidence = steps.reduce((sum, step) => sum + step.confidence, 0);
    return totalConfidence / steps.length;
  }

  /**
   * ë°©ë²•ë¡  ì„¤ëª… ìƒì„±
   */
  private generateMethodologyDescription(): string {
    const depth = this.config.analysisDepth;
    const stepCount = this.config.maxSteps;
    
    return `Deep Research Methodology: ${depth === 'basic' ? 'Basic' : depth === 'intermediate' ? 'Intermediate' : 'Advanced'} Analysis (${stepCount} steps)`;
  }

  /**
   * ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  private getSystemPrompt(): string {
    return `You are a professional researcher and analyst. You must perform deep and systematic analysis of the given questions.

CRITICAL FORMATTING RULES:
- Do NOT use markdown formatting (no ##, ###, **, *, etc.)
- Do NOT use emojis or special symbols
- Use plain text with clear structure using colons and bullet points
- Always detect the language of the input question and respond in the same language

If the question is in Korean, respond in Korean. If the question is in English, respond in English. If the question is in another language, respond in that language.

Analysis guidelines:
1. Maintain objective and balanced perspectives
2. Explore topics from various angles
3. Provide specific examples and evidence
4. Answer with logical and systematic structure using plain text
5. Clearly mark uncertain parts
6. Use professional terminology appropriately
7. Always respond in the same language as the input
8. Structure responses with colons and bullet points, not markdown headers

Analysis depth: ${this.config.analysisDepth}
Default language preference: ${this.config.language === 'ko' ? 'Korean' : 'English'}`;
  }

  /**
   * ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  private buildAnalysisPrompt(query: string, context: string): string {
    return `Please analyze the following question deeply and establish a systematic approach:

Question: "${query}"
${context ? `Context: ${context}` : ''}

Analysis elements:
1. Define core concepts of the question
2. Identify key perspectives to analyze
3. Consider important factors
4. Approach methodology
5. Expected complexity and difficulty

Perform systematic and in-depth analysis.`;
  }
}

/**
 * ë”¥ë¦¬ì„œì¹˜ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
 */
export class DeepResearchUtils {
  /**
   * ë”¥ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   */
  static formatResultAsMarkdown(result: DeepResearchResult): string {
    let markdown = `# Deep Research Result: ${result.query}\n\n`;
    
    markdown += `## ğŸ“Š Research Overview\n`;
    markdown += `- **Confidence**: ${(result.confidence * 100).toFixed(1)}%\n`;
    markdown += `- **Methodology**: ${result.methodology}\n`;
    markdown += `- **Analysis Steps**: ${result.steps.length} steps\n\n`;

    markdown += `## ğŸ” Analysis Process\n\n`;
    result.steps.forEach((step, index) => {
      markdown += `### ${index + 1}. ${step.title}\n`;
      markdown += `**Question**: ${step.question}\n\n`;
      markdown += `${step.analysis}\n\n`;
      markdown += `**Confidence**: ${(step.confidence * 100).toFixed(1)}%\n\n`;
    });

    markdown += `## ğŸ¯ Synthesis Analysis\n\n`;
    markdown += `${result.synthesis}\n\n`;

    markdown += `## ğŸ’¡ Final Answer\n\n`;
    markdown += `${result.finalAnswer}\n\n`;

    return markdown;
  }

  /**
   * ë”¥ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ ìš”ì•½ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   */
  static formatResultAsSummary(result: DeepResearchResult): string {
    return `**Question**: ${result.query}\n\n${result.finalAnswer}\n\n*${result.steps.length}-step deep research performed (Confidence: ${(result.confidence * 100).toFixed(1)}%)*`;
  }
}

export default DeepResearchProcessor;
